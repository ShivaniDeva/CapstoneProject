# -*- coding: utf-8 -*-
"""HIDS510_VAERSPostCOVIDAnalysis_ShivaniD_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AyDiox0H61oZx2ZC-sSzjrkjvuRj2GWr

# Main Objectives of Project

This project in its entierty aims to support the public health initative of educating pregnant women on what vaccines to take during their pregnancy to accomodate vaccination schedules. Using the Vaccine Adverse Events Reporting System (VAERS) Data set as the sole source of Data for adverse events, the unsupervised Leaning Method of Market Basket Analysis to see the associations between commonly reported symptoms in their magnitude and frequency. The Vaccines we have looked for is TDAP, Influenza, Hepatitis A, Hepatitis B, COVID-19, MMR, and HPV.

#Imports
"""

import pandas as pd
import numpy as np
from collections import Counter
import nltk
nltk.download('punkt')
from nltk.tokenize import sent_tokenize
from nltk.tokenize import word_tokenize
from nltk.probability import FreqDist
import matplotlib.pyplot as plt
import string
string.punctuation
from nltk.corpus import stopwords
nltk.download('stopwords')
stopwords = stopwords.words("english")
import sys
import sklearn
!pip install apyori
from apyori import apriori
from wordcloud import WordCloud

"""#Reading in the 2021-22 Data"""

#Reading in 2021
vaers2021_data = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/InputFiles/2021VAERSData/2021VAERSDATA.csv", encoding='cp1252')
vaers2021_symptoms = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/InputFiles/2021VAERSData/2021VAERSSYMPTOMS.csv")
vaers2021_vacc = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/InputFiles/2021VAERSData/2021VAERSVAX.csv",encoding='cp1252')

#Reading in 2022
vaers2022_data = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/InputFiles/2022VAERSData/2022VAERSDATA.csv", encoding='cp1252')
vaers2022_symptoms = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/InputFiles/2022VAERSData/2022VAERSSYMPTOMS.csv")
vaers2022_vacc = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/InputFiles/2022VAERSData/2022VAERSVAX.csv",encoding='cp1252')

"""#Combining the Data
There are 3 steps to this part of combining the data. The first step includes amalgamating all of the years of data by their respective file formats. 3 separate data frames are created which contain the data (free text), symptoms, and vaccinations for the patients. From there using the data files I filtered down by sex == F. The pregnancy data was a combination of the cleaned vaers data but used two different columns and contatiated that. Then I combined the pregnancy data and the vaccines and symptoms data and dropped unnecessary columns.
"""

vaers_data_postCovid = pd.concat([vaers2021_data, vaers2022_data]).drop_duplicates('VAERS_ID').fillna("")
vaers_symptoms_postCovid = pd.concat([vaers2021_symptoms, vaers2022_symptoms]).drop_duplicates('VAERS_ID').fillna("")
vaers_vacc_postCovid = pd.concat([vaers2021_vacc, vaers2022_vacc]).drop_duplicates('VAERS_ID').fillna("")

vaers_data_cleanedPostCOVID =  vaers_data_postCovid[(vaers_data_postCovid["SEX"]== "F") | (vaers_data_postCovid["SEX"]== "f")].copy().fillna("")

pregnancy_data1_postCOVID = vaers_data_cleanedPostCOVID[vaers_data_cleanedPostCOVID['SYMPTOM_TEXT'].str.contains('preg')].copy()
pregnancy_data2_postCOVID= vaers_data_cleanedPostCOVID[vaers_data_cleanedPostCOVID['CUR_ILL'].str.contains('preg')].copy()

pregnancy_data1_postCOVID

pregnancy_data2_postCOVID

combined_pregnancy_data_postCOVID = pd.concat([pregnancy_data1_postCOVID,pregnancy_data2_postCOVID]).drop_duplicates('VAERS_ID').fillna("")

combined_pregnancy_data_postCOVID

combined_pregnancy_data_cleaned_postCOVID = combined_pregnancy_data_postCOVID.drop(columns = ['STATE', 'AGE_YRS', 'CAGE_YR', 'CAGE_MO', 'SEX',
       'RPT_DATE', 'DIED', 'DATEDIED', 'L_THREAT', 'ER_VISIT',
       'HOSPITAL', 'HOSPDAYS', 'X_STAY', 'DISABLE', 'RECOVD', 'VAX_DATE',
       'ONSET_DATE', 'NUMDAYS', 'LAB_DATA', 'V_ADMINBY', 'V_FUNDBY',
       'OTHER_MEDS', 'HISTORY', 'PRIOR_VAX', 'SPLTTYPE',
       'FORM_VERS', 'TODAYS_DATE', 'BIRTH_DEFECT', 'OFC_VISIT', 'ER_ED_VISIT'])

combined_pregnancy_data_cleaned_postCOVID

vaers_symp_vacc_postCOVID = pd.merge(vaers_symptoms_postCovid,vaers_vacc_postCovid, on= "VAERS_ID").drop_duplicates('VAERS_ID').fillna("")
post_covid_data = pd.merge(vaers_data_cleanedPostCOVID,vaers_symp_vacc_postCOVID,on= "VAERS_ID").drop_duplicates('VAERS_ID').fillna("")

cleaned_post_covid_data = post_covid_data.drop(columns= ['STATE','CAGE_YR', 'CAGE_MO', 'SEX',
       'RPT_DATE', 'SYMPTOM_TEXT', 'DIED', 'DATEDIED', 'L_THREAT', 'ER_VISIT',
       'HOSPITAL', 'HOSPDAYS', 'X_STAY', 'DISABLE', 'RECOVD', 'VAX_DATE',
       'ONSET_DATE', 'NUMDAYS', 'LAB_DATA', 'V_ADMINBY', 'V_FUNDBY',
       'OTHER_MEDS', 'CUR_ILL', 'HISTORY', 'PRIOR_VAX', 'SPLTTYPE',
       'FORM_VERS', 'TODAYS_DATE', 'BIRTH_DEFECT', 'OFC_VISIT', 'ER_ED_VISIT',
       'ALLERGIES', 'SYMPTOMVERSION1','SYMPTOMVERSION2','SYMPTOMVERSION3','SYMPTOMVERSION4','SYMPTOMVERSION5'])

final_PostCOVID_pregnancyData = pd.merge(cleaned_post_covid_data,combined_pregnancy_data_cleaned_postCOVID,on= "VAERS_ID").drop_duplicates('VAERS_ID').fillna("")

final_PostCOVID_pregnancyData

"""### For individual vaccines: Searching through the dataframes"""

final_PostCOVID_pregnancyData_TDAP = final_PostCOVID_pregnancyData[(final_PostCOVID_pregnancyData['VAX_NAME'].str.contains('TDAP'))].copy()

final_PostCOVID_pregnancyData_TDAP

len(final_PostCOVID_pregnancyData_TDAP)

final_PostCOVID_pregnancyData_FLU = final_PostCOVID_pregnancyData[(final_PostCOVID_pregnancyData['VAX_NAME'].str.contains('FLU'))].copy()

final_PostCOVID_pregnancyData_FLU

final_PostCOVID_pregnancyData_HEPA = final_PostCOVID_pregnancyData[(final_PostCOVID_pregnancyData['VAX_NAME'].str.contains('HEP A'))].copy()

final_PostCOVID_pregnancyData_HEPA

final_PostCOVID_pregnancyData_HEPB = final_PostCOVID_pregnancyData[(final_PostCOVID_pregnancyData['VAX_NAME'].str.contains('HEP B'))].copy()

final_PostCOVID_pregnancyData_HEPB

final_pregnancyData_COVID = final_PostCOVID_pregnancyData[(final_PostCOVID_pregnancyData['VAX_NAME'].str.contains('COVID'))].copy()

final_pregnancyData_COVID

final_PostCOVID_pregnancyData_MMR = final_PostCOVID_pregnancyData[(final_PostCOVID_pregnancyData['VAX_NAME'].str.contains('MMR'))].copy()

final_PostCOVID_pregnancyData_MMR

len(final_PostCOVID_pregnancyData_MMR)

final_PostCOVID_pregnancyData_HPV = final_PostCOVID_pregnancyData[(final_PostCOVID_pregnancyData['VAX_NAME'].str.contains('HPV'))].copy()

final_PostCOVID_pregnancyData_HPV

len(final_PostCOVID_pregnancyData_HPV)

"""#NLP& Frequency Distrubutions

####TDAP
"""

import re
from nltk.stem import PorterStemmer

def process_symptoms(df):

    df['SYMPTOM1_processed'], df['SYMPTOM2_processed'], df['SYMPTOM3_processed'], df['SYMPTOM4_processed'], df['SYMPTOM5_processed'], df['all_symptoms_processed'] = "", "", "", "", "", ""

    # replace na
    df['SYMPTOM1'] = df['SYMPTOM1'].fillna("")
    df['SYMPTOM2'] = df['SYMPTOM2'].fillna("")
    df['SYMPTOM3'] = df['SYMPTOM3'].fillna("")
    df['SYMPTOM4'] = df['SYMPTOM4'].fillna("")
    df['SYMPTOM5'] = df['SYMPTOM5'].fillna("")

    # to lowercase
    symp_1 = [v.lower() for v in df['SYMPTOM1']]
    symp_2 = [v.lower() for v in df['SYMPTOM2']]
    symp_3 = [v.lower() for v in df['SYMPTOM3']]
    symp_4 = [v.lower() for v in df['SYMPTOM4']]
    symp_5 = [v.lower() for v in df['SYMPTOM5']]

    # remove any character other than alphabets and white spaces
    symp_1 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_1]
    symp_2 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_2]
    symp_3 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_3]
    symp_4 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_4]
    symp_5 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_5]

    # remove stopwords
    nltk.download("stopwords")
    stop_words = set(stopwords)
    symp_1 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_1]
    symp_2 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_2]
    symp_3 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_3]
    symp_4 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_4]
    symp_5 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_5]

    # word stemming
    ps = PorterStemmer()
    symp_1 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_1]
    symp_2 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_2]
    symp_3 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_3]
    symp_4 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_4]
    symp_5 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_5]

    # remove extra white spaces
    symp_1 = [re.sub(" +", " ", v) for v in symp_1]
    symp_2 = [re.sub(" +", " ", v) for v in symp_2]
    symp_3 = [re.sub(" +", " ", v) for v in symp_3]
    symp_4 = [re.sub(" +", " ", v) for v in symp_4]
    symp_5 = [re.sub(" +", " ", v) for v in symp_5]

    # save the preprocessed symptoms
    df['SYMPTOM1_processed'] = symp_1
    df['SYMPTOM2_processed'] = symp_2
    df['SYMPTOM3_processed'] = symp_3
    df['SYMPTOM4_processed'] = symp_4
    df['SYMPTOM5_processed'] = symp_5

    # concatenate the five columns of processed symptoms
    for i in range(0, df.shape[0]):
        if df["SYMPTOM1_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + df["SYMPTOM1_processed"].iloc[i]
        if df["SYMPTOM2_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM2_processed"].iloc[i]
        if df["SYMPTOM3_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM3_processed"].iloc[i]
        if df["SYMPTOM4_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM4_processed"].iloc[i]
        if df["SYMPTOM5_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM5_processed"].iloc[i]

    # remove extra white spaces and strip the final strings
    df["all_symptoms_processed"] = [re.sub(" +", " ", v) for v in df["all_symptoms_processed"]]
    df["all_symptoms_processed"] = [v.strip() for v in df["all_symptoms_processed"]]

    return df

#Then, call the function to process the symptoms:

TDAP_PostCOVID_Data = process_symptoms(final_PostCOVID_pregnancyData_TDAP)

# Filtering out keys that contain the specified substring. Need to remove Exposur Pregnanc
def remove_substring_from_dict(d, substring):
    return {key: value for key, value in d.items() if substring not in key}
# Creating word Clouds to see the most common words in the TDAP data
TDAP_PostCOVID_WC = TDAP_PostCOVID_Data['all_symptoms_processed'].value_counts().to_dict()
TDAP_PostCOVID_WC = remove_substring_from_dict(TDAP_PostCOVID_WC, "exposur pregnanc")
wc = WordCloud(width=800, height=400,background_color = "white").generate_from_frequencies(TDAP_PostCOVID_WC)

# plot the WordCloud image
plt.figure(figsize = (10, 10), facecolor = None)
plt.imshow(wc)
plt.axis("off")
plt.title("TDAP Post COVID-19 Symptom Word Cloud", fontsize= 30)
plt.show()

# Getting Frequencies of Symptoms
import collections
def get_most_frequent_values(list_of_values, n_most_frequent):
    counter_values = collections.Counter(list_of_values)
    most_common = counter_values.most_common(n_most_frequent) # most_common() produces k frequently encountered input values and their respective counts.
    counter_frequent_keys = [list(counter_values.most_common(n_most_frequent))[i][0] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    counter_frequent_counts = [list(counter_values.most_common(n_most_frequent))[i][1] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    # save in a data frame
    df = pd.DataFrame(columns = ["keys", "counts"])
    df["keys"] = counter_frequent_keys
    df["counts"] = counter_frequent_counts
    return df, counter_frequent_keys, counter_frequent_counts
n_most_frequent = 20
df_freq_symptoms_TDAP_PC, freq_symptoms, freq_symptoms_count = get_most_frequent_values(TDAP_PostCOVID_Data["all_symptoms_processed"], n_most_frequent)

df_freq_symptoms_TDAP_PC

# Storing this in a dictionary is the best way to create a graph of the frequency distribution. Terms were copied directly from the list above.
df_freq_symptoms_TDAP_PC_dict = {
    'keys': ['exposur pregnanc, advers event', 'exposur pregnanc, extra dose administ', 'exposur pregnanc, vomit',
             'abdomin pain upper, diarrhoea, nausea, vomit', 'arthralgia, blood pressur increas, bursa disorder',
             'chill, exposur pregnanc, headach, pain, pain extrem', 'exposur pregnanc, tinnitu',
             'exposur pregnanc, inappropri schedul product administr', 'exposur pregnanc, incorrect dose administ, advers event',
             'exposur pregnanc, pregnanc', 'limb injuri, matern exposur pregnanc',
             'fatigu, intens care, neuropathi peripher, pain', 'bell palsi, blood test abnorm, exposur pregnanc, pregnanc',
             'exposur pregnanc, prematur labour', 'blind transient, blood test, central vision loss, depress',
             'exposur pregnanc, third trimest pregnanc', 'antibodi test neg, chlamydia test neg, congenital anomaly',
             'deliveri, exposur pregnanc, foetal death, labour', 'abdomin pain, abdomin pain upper, blood albumin, hepatic enzyme abnorm',
             'exposur pregnanc, product storag error'],
    'counts': [4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
}

TDAP_PC_df = pd.DataFrame(df_freq_symptoms_TDAP_PC_dict)

TDAP_PC_df.sort_values(by='counts', ascending=False, inplace=True)

# Creating the bar plot
plt.figure(figsize=(10, 6))
plt.barh(TDAP_PC_df['keys'], TDAP_PC_df['counts'], color='dodgerblue', alpha=0.7)
plt.xticks(rotation=90, fontsize=8)
plt.xlabel('Frequency')
plt.ylabel('Symptoms Commonly Reported Together')
plt.xlim(0, max(TDAP_PC_df['counts']) + 5)
plt.title('TDAP Post COVID-19 Symptom Frequency', fontsize = 30)
plt.grid(axis='y', alpha=0.7)
plt.tight_layout()

plt.show()

"""####Flu"""

import re
from nltk.stem import PorterStemmer

def process_symptoms(df):

    df['SYMPTOM1_processed'], df['SYMPTOM2_processed'], df['SYMPTOM3_processed'], df['SYMPTOM4_processed'], df['SYMPTOM5_processed'], df['all_symptoms_processed'] = "", "", "", "", "", ""

    # replace na
    df['SYMPTOM1'] = df['SYMPTOM1'].fillna("")
    df['SYMPTOM2'] = df['SYMPTOM2'].fillna("")
    df['SYMPTOM3'] = df['SYMPTOM3'].fillna("")
    df['SYMPTOM4'] = df['SYMPTOM4'].fillna("")
    df['SYMPTOM5'] = df['SYMPTOM5'].fillna("")

    # to lowercase
    symp_1 = [v.lower() for v in df['SYMPTOM1']]
    symp_2 = [v.lower() for v in df['SYMPTOM2']]
    symp_3 = [v.lower() for v in df['SYMPTOM3']]
    symp_4 = [v.lower() for v in df['SYMPTOM4']]
    symp_5 = [v.lower() for v in df['SYMPTOM5']]

    # remove any character other than alphabets and white spaces
    symp_1 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_1]
    symp_2 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_2]
    symp_3 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_3]
    symp_4 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_4]
    symp_5 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_5]

    # remove stopwords
    nltk.download("stopwords")
    stop_words = set(stopwords)
    symp_1 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_1]
    symp_2 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_2]
    symp_3 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_3]
    symp_4 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_4]
    symp_5 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_5]

    # word stemming
    ps = PorterStemmer()
    symp_1 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_1]
    symp_2 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_2]
    symp_3 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_3]
    symp_4 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_4]
    symp_5 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_5]

    # remove extra white spaces
    symp_1 = [re.sub(" +", " ", v) for v in symp_1]
    symp_2 = [re.sub(" +", " ", v) for v in symp_2]
    symp_3 = [re.sub(" +", " ", v) for v in symp_3]
    symp_4 = [re.sub(" +", " ", v) for v in symp_4]
    symp_5 = [re.sub(" +", " ", v) for v in symp_5]

    # save the preprocessed symptoms
    df['SYMPTOM1_processed'] = symp_1
    df['SYMPTOM2_processed'] = symp_2
    df['SYMPTOM3_processed'] = symp_3
    df['SYMPTOM4_processed'] = symp_4
    df['SYMPTOM5_processed'] = symp_5

    # concatenate the five columns of processed symptoms
    for i in range(0, df.shape[0]):
        if df["SYMPTOM1_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + df["SYMPTOM1_processed"].iloc[i]
        if df["SYMPTOM2_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM2_processed"].iloc[i]
        if df["SYMPTOM3_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM3_processed"].iloc[i]
        if df["SYMPTOM4_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM4_processed"].iloc[i]
        if df["SYMPTOM5_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM5_processed"].iloc[i]

    # remove extra white spaces and strip the final strings
    df["all_symptoms_processed"] = [re.sub(" +", " ", v) for v in df["all_symptoms_processed"]]
    df["all_symptoms_processed"] = [v.strip() for v in df["all_symptoms_processed"]]

    return df

#Then, call the function to process the symptoms:

FLU_PostCOVID_Data = process_symptoms(final_PostCOVID_pregnancyData_FLU)

# Filtering out keys that contain the specified substring. Need to remove Exposur Pregnanc
def remove_substring_from_dict(d, substring):
    return {key: value for key, value in d.items() if substring not in key}
# Creating word Clouds to see the most common words in the Flu data
FLU_PostCOVID_WC = FLU_PostCOVID_Data['all_symptoms_processed'].value_counts().to_dict()
FLU_PostCOVID_WC = remove_substring_from_dict(FLU_PostCOVID_WC, "exposur pregnanc")
wc = WordCloud(width=800, height=400,background_color = "white").generate_from_frequencies(FLU_PostCOVID_WC)

# plot the WordCloud image
plt.figure(figsize = (10, 10), facecolor = None)
plt.imshow(wc)
plt.axis("off")
plt.title("Influenza Post COVID-19 Symptom Word Cloud", fontsize = 30)
plt.show()

import collections
def get_most_frequent_values(list_of_values, n_most_frequent):
    counter_values = collections.Counter(list_of_values)
    most_common = counter_values.most_common(n_most_frequent) # most_common() produces k frequently encountered input values and their respective counts.
    counter_frequent_keys = [list(counter_values.most_common(n_most_frequent))[i][0] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    counter_frequent_counts = [list(counter_values.most_common(n_most_frequent))[i][1] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    # save in a data frame
    df = pd.DataFrame(columns = ["keys", "counts"])
    df["keys"] = counter_frequent_keys
    df["counts"] = counter_frequent_counts
    return df, counter_frequent_keys, counter_frequent_counts
n_most_frequent = 20
df_freq_symptoms_FLU_PC, freq_symptoms, freq_symptoms_count = get_most_frequent_values(FLU_PostCOVID_Data["all_symptoms_processed"], n_most_frequent)

df_freq_symptoms_FLU_PC

# Storing this in a dictionary is the best way to create a graph of the frequency distribution. Terms were copied directly from the list above.
df_freq_symptoms_FLU_PC_dict = {
    'keys': ['exposur pregnanc', 'exposur pregnanc, advers event', 'expir product administ, exposur pregnanc',
             'expir product administ, exposur pregnanc, advers event',
             'exposur pregnanc, wrong product administ', 'foetal exposur pregnanc, larg date babi',
             'exposur pregnanc, pain extrem', 'matern exposur pregnanc', 'inject site rash, rash erythemat',
             'alpha foetoprotein abnorm, exposur pregnanc, foetal exposur pregnanc',
             'exposur pregnanc, neuropathi peripher', 'apgar score low, foetal exposur pregnanc',
             'apgar score normal, foetal exposur pregnanc, larg date babi',
             'influenza, matern exposur pregnanc', 'asthenia, blood glucos normal, commun disord, exposur pregnanc',
             'caesarean section, exposur pregnanc, haemoglobin abnorm', 'alpha foetoprotein, exposur pregnanc, prematur birth',
             'foetal exposur pregnanc, prematur babi, prematur labour',
             'bacteri test posit, beta haemolytic streptococcus test posit, exposur pregnanc',
             'amniocentesi normal, chromosom analysi normal, exposur pregnanc'],
    'counts': [21, 5, 4, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
}

FLU_PC_df = pd.DataFrame(df_freq_symptoms_FLU_PC_dict)

FLU_PC_df.sort_values(by='counts', ascending=False, inplace=True)

# Creating the bar plot
plt.figure(figsize=(14, 8))
plt.barh(FLU_PC_df['keys'], FLU_PC_df['counts'], color='dodgerblue', alpha=0.7)
plt.xticks(rotation=90, fontsize=8)
plt.xlabel('Frequency')
plt.ylabel('Symptoms Commonly Reported Together')
plt.xlim(0, max(FLU_PC_df['counts']) + 5)
plt.title('Inluenza Post COVID-19 Symptom Frequency', fontsize = 30)
plt.grid(axis='y', alpha=0.7)

plt.show()

"""####HepA"""

import re
from nltk.stem import PorterStemmer

def process_symptoms(df):

    df['SYMPTOM1_processed'], df['SYMPTOM2_processed'], df['SYMPTOM3_processed'], df['SYMPTOM4_processed'], df['SYMPTOM5_processed'], df['all_symptoms_processed'] = "", "", "", "", "", ""

    # replace na
    df['SYMPTOM1'] = df['SYMPTOM1'].fillna("")
    df['SYMPTOM2'] = df['SYMPTOM2'].fillna("")
    df['SYMPTOM3'] = df['SYMPTOM3'].fillna("")
    df['SYMPTOM4'] = df['SYMPTOM4'].fillna("")
    df['SYMPTOM5'] = df['SYMPTOM5'].fillna("")

    # to lowercase
    symp_1 = [v.lower() for v in df['SYMPTOM1']]
    symp_2 = [v.lower() for v in df['SYMPTOM2']]
    symp_3 = [v.lower() for v in df['SYMPTOM3']]
    symp_4 = [v.lower() for v in df['SYMPTOM4']]
    symp_5 = [v.lower() for v in df['SYMPTOM5']]

    # remove any character other than alphabets and white spaces
    symp_1 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_1]
    symp_2 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_2]
    symp_3 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_3]
    symp_4 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_4]
    symp_5 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_5]

    # remove stopwords
    nltk.download("stopwords")
    stop_words = set(stopwords)
    symp_1 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_1]
    symp_2 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_2]
    symp_3 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_3]
    symp_4 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_4]
    symp_5 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_5]

    # word stemming
    ps = PorterStemmer()
    symp_1 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_1]
    symp_2 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_2]
    symp_3 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_3]
    symp_4 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_4]
    symp_5 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_5]

    # remove extra white spaces
    symp_1 = [re.sub(" +", " ", v) for v in symp_1]
    symp_2 = [re.sub(" +", " ", v) for v in symp_2]
    symp_3 = [re.sub(" +", " ", v) for v in symp_3]
    symp_4 = [re.sub(" +", " ", v) for v in symp_4]
    symp_5 = [re.sub(" +", " ", v) for v in symp_5]

    # save the preprocessed symptoms
    df['SYMPTOM1_processed'] = symp_1
    df['SYMPTOM2_processed'] = symp_2
    df['SYMPTOM3_processed'] = symp_3
    df['SYMPTOM4_processed'] = symp_4
    df['SYMPTOM5_processed'] = symp_5

    # concatenate the five columns of processed symptoms
    for i in range(0, df.shape[0]):
        if df["SYMPTOM1_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + df["SYMPTOM1_processed"].iloc[i]
        if df["SYMPTOM2_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM2_processed"].iloc[i]
        if df["SYMPTOM3_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM3_processed"].iloc[i]
        if df["SYMPTOM4_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM4_processed"].iloc[i]
        if df["SYMPTOM5_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM5_processed"].iloc[i]

    # remove extra white spaces and strip the final strings
    df["all_symptoms_processed"] = [re.sub(" +", " ", v) for v in df["all_symptoms_processed"]]
    df["all_symptoms_processed"] = [v.strip() for v in df["all_symptoms_processed"]]

    return df

#Then, call the function to process the symptoms:

HEPA_PostCOVID_Data = process_symptoms(final_PostCOVID_pregnancyData_HEPA)

# Filtering out keys that contain the specified substring. Need to remove Exposur Pregnanc
def remove_substring_from_dict(d, substring):
    return {key: value for key, value in d.items() if substring not in key}
# Creating word Clouds to see the most common words in the HepA data
HEPA_PostCOVID_WC = HEPA_PostCOVID_Data['all_symptoms_processed'].value_counts().to_dict()
HEPA_PostCOVID_WC = remove_substring_from_dict(HEPA_PostCOVID_WC, "exposur pregnanc")
wc = WordCloud(width=800, height=400,background_color = "white").generate_from_frequencies(HEPA_PostCOVID_WC)

# plot the WordCloud image
plt.figure(figsize = (10, 10), facecolor = None)
plt.imshow(wc)
plt.axis("off")
plt.title("Hepatitis A Post COVID-19 Symptom Word Cloud", fontsize = 25)
plt.show()

import collections
def get_most_frequent_values(list_of_values, n_most_frequent):
    counter_values = collections.Counter(list_of_values)
    most_common = counter_values.most_common(n_most_frequent) # most_common() produces k frequently encountered input values and their respective counts.
    counter_frequent_keys = [list(counter_values.most_common(n_most_frequent))[i][0] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    counter_frequent_counts = [list(counter_values.most_common(n_most_frequent))[i][1] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    # save in a data frame
    df = pd.DataFrame(columns = ["keys", "counts"])
    df["keys"] = counter_frequent_keys
    df["counts"] = counter_frequent_counts
    return df, counter_frequent_keys, counter_frequent_counts
n_most_frequent = 20
df_freq_symptoms_HEPA_PC, freq_symptoms, freq_symptoms_count = get_most_frequent_values(HEPA_PostCOVID_Data["all_symptoms_processed"], n_most_frequent)

df_freq_symptoms_HEPA_PC

# Storing this in a dictionary is the best way to create a graph of the frequency distribution. Terms were copied directly from the list above.
df_freq_symptoms_HEPA_PC_dict = {
    'keys': ['anxieti, blood glucos normal, eye movement disord, exposur pregnanc',
             'exposur pregnanc, advers event'],
    'counts': [1, 1]
}

HEPA_PC_df = pd.DataFrame(df_freq_symptoms_HEPA_PC_dict)

HEPA_PC_df.sort_values(by='counts', ascending=False, inplace=True)

# Creating the bar plot
plt.figure(figsize=(10, 6))
plt.barh(HEPA_PC_df['keys'], HEPA_PC_df['counts'], color='dodgerblue', alpha=0.7)
plt.xticks(rotation=90, fontsize=8)
plt.xlabel('Frequency')
plt.ylabel('Symptoms Commonly Reported Together')
plt.xlim(0, max(HEPA_PC_df['counts']) + 5)
plt.title('Hepatitis A Post COVID-19 Symptom Frequency', fontsize = 30)
plt.grid(axis='y', alpha=0.7)
plt.tight_layout()

plt.show()

"""####HepB"""

import re
from nltk.stem import PorterStemmer

def process_symptoms(df):

    df['SYMPTOM1_processed'], df['SYMPTOM2_processed'], df['SYMPTOM3_processed'], df['SYMPTOM4_processed'], df['SYMPTOM5_processed'], df['all_symptoms_processed'] = "", "", "", "", "", ""

    # replace na
    df['SYMPTOM1'] = df['SYMPTOM1'].fillna("")
    df['SYMPTOM2'] = df['SYMPTOM2'].fillna("")
    df['SYMPTOM3'] = df['SYMPTOM3'].fillna("")
    df['SYMPTOM4'] = df['SYMPTOM4'].fillna("")
    df['SYMPTOM5'] = df['SYMPTOM5'].fillna("")

    # to lowercase
    symp_1 = [v.lower() for v in df['SYMPTOM1']]
    symp_2 = [v.lower() for v in df['SYMPTOM2']]
    symp_3 = [v.lower() for v in df['SYMPTOM3']]
    symp_4 = [v.lower() for v in df['SYMPTOM4']]
    symp_5 = [v.lower() for v in df['SYMPTOM5']]

    # remove any character other than alphabets and white spaces
    symp_1 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_1]
    symp_2 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_2]
    symp_3 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_3]
    symp_4 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_4]
    symp_5 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_5]

    # remove stopwords
    nltk.download("stopwords")
    stop_words = set(stopwords)
    symp_1 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_1]
    symp_2 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_2]
    symp_3 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_3]
    symp_4 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_4]
    symp_5 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_5]

    # word stemming
    ps = PorterStemmer()
    symp_1 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_1]
    symp_2 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_2]
    symp_3 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_3]
    symp_4 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_4]
    symp_5 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_5]

    # remove extra white spaces
    symp_1 = [re.sub(" +", " ", v) for v in symp_1]
    symp_2 = [re.sub(" +", " ", v) for v in symp_2]
    symp_3 = [re.sub(" +", " ", v) for v in symp_3]
    symp_4 = [re.sub(" +", " ", v) for v in symp_4]
    symp_5 = [re.sub(" +", " ", v) for v in symp_5]

    # save the preprocessed symptoms
    df['SYMPTOM1_processed'] = symp_1
    df['SYMPTOM2_processed'] = symp_2
    df['SYMPTOM3_processed'] = symp_3
    df['SYMPTOM4_processed'] = symp_4
    df['SYMPTOM5_processed'] = symp_5

    # concatenate the five columns of processed symptoms
    for i in range(0, df.shape[0]):
        if df["SYMPTOM1_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + df["SYMPTOM1_processed"].iloc[i]
        if df["SYMPTOM2_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM2_processed"].iloc[i]
        if df["SYMPTOM3_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM3_processed"].iloc[i]
        if df["SYMPTOM4_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM4_processed"].iloc[i]
        if df["SYMPTOM5_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM5_processed"].iloc[i]

    # remove extra white spaces and strip the final strings
    df["all_symptoms_processed"] = [re.sub(" +", " ", v) for v in df["all_symptoms_processed"]]
    df["all_symptoms_processed"] = [v.strip() for v in df["all_symptoms_processed"]]

    return df

#Then, call the function to process the symptoms:

HEPB_PostCOVID_Data = process_symptoms(final_PostCOVID_pregnancyData_HEPB)

# Filtering out keys that contain the specified substring. Need to remove Exposur Pregnanc
def remove_substring_from_dict(d, substring):
    return {key: value for key, value in d.items() if substring not in key}
# Creating word Clouds to see the most common words in the HepB data
HEPB_PostCOVID_WC = HEPB_PostCOVID_Data['all_symptoms_processed'].value_counts().to_dict()
HEPB_PostCOVID_WC = remove_substring_from_dict(HEPB_PostCOVID_WC, "exposur pregnanc")
wc = WordCloud(width=800, height=400,background_color = "white").generate_from_frequencies(HEPB_PostCOVID_WC)

# plot the WordCloud image
plt.figure(figsize = (10, 10), facecolor = None)
plt.imshow(wc)
plt.axis("off")
plt.title("Hepatitis B Post COVID-19 Symptom Word Cloud", fontsize = 25)
plt.show()

import collections
def get_most_frequent_values(list_of_values, n_most_frequent):
    counter_values = collections.Counter(list_of_values)
    most_common = counter_values.most_common(n_most_frequent) # most_common() produces k frequently encountered input values and their respective counts.
    counter_frequent_keys = [list(counter_values.most_common(n_most_frequent))[i][0] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    counter_frequent_counts = [list(counter_values.most_common(n_most_frequent))[i][1] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    # save in a data frame
    df = pd.DataFrame(columns = ["keys", "counts"])
    df["keys"] = counter_frequent_keys
    df["counts"] = counter_frequent_counts
    return df, counter_frequent_keys, counter_frequent_counts
n_most_frequent = 20
df_freq_symptoms_HEPB_PC, freq_symptoms, freq_symptoms_count = get_most_frequent_values(HEPB_PostCOVID_Data["all_symptoms_processed"], n_most_frequent)

df_freq_symptoms_HEPB_PC

# Storing this in a dictionary is the best way to create a graph of the frequency distribution. Terms were copied directly from the list above.
df_freq_symptoms_HEPB_PC_dict = {
    'keys': [
        'interchang vaccin product, advers event',
        'antinuclear antibodi neg, arthriti, aspir joint adhes',
        'limb mass',
        'cardiac murmur, exposur pregnanc'
    ],
    'counts': [1, 1, 1, 1]
}

HEPB_PC_df = pd.DataFrame(df_freq_symptoms_HEPB_PC_dict)

HEPB_PC_df.sort_values(by='counts', ascending=False, inplace=True)

# Creating the bar plot
plt.figure(figsize=(10, 6))
plt.barh(HEPB_PC_df['keys'], HEPB_PC_df['counts'], color='dodgerblue', alpha=0.7)
plt.xticks(rotation=90, fontsize=10)
plt.xlabel('Frequency')
plt.ylabel('Symptoms Commonly Reported Together')
plt.xlim(0, max(HEPB_PC_df['counts']) + 5)
plt.title('Hepatitis B Post COVID-19 Symptom Frequency', fontsize = 30)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()

plt.show()

"""####COVID-19"""

import re
from nltk.stem import PorterStemmer

def process_symptoms(df):

    df['SYMPTOM1_processed'], df['SYMPTOM2_processed'], df['SYMPTOM3_processed'], df['SYMPTOM4_processed'], df['SYMPTOM5_processed'], df['all_symptoms_processed'] = "", "", "", "", "", ""

    # replace na
    df['SYMPTOM1'] = df['SYMPTOM1'].fillna("")
    df['SYMPTOM2'] = df['SYMPTOM2'].fillna("")
    df['SYMPTOM3'] = df['SYMPTOM3'].fillna("")
    df['SYMPTOM4'] = df['SYMPTOM4'].fillna("")
    df['SYMPTOM5'] = df['SYMPTOM5'].fillna("")

    # to lowercase
    symp_1 = [v.lower() for v in df['SYMPTOM1']]
    symp_2 = [v.lower() for v in df['SYMPTOM2']]
    symp_3 = [v.lower() for v in df['SYMPTOM3']]
    symp_4 = [v.lower() for v in df['SYMPTOM4']]
    symp_5 = [v.lower() for v in df['SYMPTOM5']]

    # remove any character other than alphabets and white spaces
    symp_1 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_1]
    symp_2 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_2]
    symp_3 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_3]
    symp_4 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_4]
    symp_5 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_5]

    # remove stopwords
    nltk.download("stopwords")
    stop_words = set(stopwords)
    symp_1 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_1]
    symp_2 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_2]
    symp_3 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_3]
    symp_4 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_4]
    symp_5 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_5]

    # word stemming
    ps = PorterStemmer()
    symp_1 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_1]
    symp_2 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_2]
    symp_3 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_3]
    symp_4 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_4]
    symp_5 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_5]

    # remove extra white spaces
    symp_1 = [re.sub(" +", " ", v) for v in symp_1]
    symp_2 = [re.sub(" +", " ", v) for v in symp_2]
    symp_3 = [re.sub(" +", " ", v) for v in symp_3]
    symp_4 = [re.sub(" +", " ", v) for v in symp_4]
    symp_5 = [re.sub(" +", " ", v) for v in symp_5]

    # save the preprocessed symptoms
    df['SYMPTOM1_processed'] = symp_1
    df['SYMPTOM2_processed'] = symp_2
    df['SYMPTOM3_processed'] = symp_3
    df['SYMPTOM4_processed'] = symp_4
    df['SYMPTOM5_processed'] = symp_5

    # concatenate the five columns of processed symptoms
    for i in range(0, df.shape[0]):
        if df["SYMPTOM1_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + df["SYMPTOM1_processed"].iloc[i]
        if df["SYMPTOM2_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM2_processed"].iloc[i]
        if df["SYMPTOM3_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM3_processed"].iloc[i]
        if df["SYMPTOM4_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM4_processed"].iloc[i]
        if df["SYMPTOM5_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM5_processed"].iloc[i]

    # remove extra white spaces and strip the final strings
    df["all_symptoms_processed"] = [re.sub(" +", " ", v) for v in df["all_symptoms_processed"]]
    df["all_symptoms_processed"] = [v.strip() for v in df["all_symptoms_processed"]]

    return df

#Then, call the function to process the symptoms:

COVID_Data = process_symptoms(final_pregnancyData_COVID)

# Filtering out keys that contain the specified substring. Need to remove Exposur Pregnanc
def remove_substring_from_dict(d, substring):
    return {key: value for key, value in d.items() if substring not in key}
# Creating word Clouds to see the most common words in the COVID data
COVID_Data_WC = COVID_Data['all_symptoms_processed'].value_counts().to_dict()
COVID_Data_WC = remove_substring_from_dict(COVID_Data_WC, "exposur pregnanc")
wc = WordCloud(width=800, height=400,background_color = "white").generate_from_frequencies(COVID_Data_WC)

# plot the WordCloud image
plt.figure(figsize = (10, 10), facecolor = None)
plt.imshow(wc)
plt.axis("off")
plt.title("COVID-19 Symptom Word Cloud", fontsize = 30)
plt.show()

COVID_Data

import collections
def get_most_frequent_values(list_of_values, n_most_frequent):
    counter_values = collections.Counter(list_of_values)
    most_common = counter_values.most_common(n_most_frequent) # most_common() produces k frequently encountered input values and their respective counts.
    counter_frequent_keys = [list(counter_values.most_common(n_most_frequent))[i][0] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    counter_frequent_counts = [list(counter_values.most_common(n_most_frequent))[i][1] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    # save in a data frame
    df = pd.DataFrame(columns = ["keys", "counts"])
    df["keys"] = counter_frequent_keys
    df["counts"] = counter_frequent_counts
    return df, counter_frequent_keys, counter_frequent_counts
n_most_frequent = 20
df_freq_symptoms_COVID, freq_symptoms, freq_symptoms_count = get_most_frequent_values(COVID_Data["all_symptoms_processed"], n_most_frequent)

df_freq_symptoms_COVID

# Storing this in a dictionary is the best way to create a graph of the frequency distribution. Terms were copied directly from the list above.
df_freq_symptoms_COVID_dict = {
    'keys': [
        'matern exposur pregnanc',
        'exposur pregnanc',
        'lymphadenopathi',
        'pain extrem',
        'vaccin site pain',
        'rash',
        'herp zoster',
        'tinnitu',
        'urticaria',
        'headach',
        'matern exposur pregnanc, pregnanc test',
        'covid, sar cov test, vaccin failur',
        'menstruat irregular',
        'abort spontan, exposur pregnanc',
        'lymph node pain, lymphadenopathi',
        'menstruat delay',
        'dizzi',
        'diarrhoea',
        'covid, drug ineffect, sar cov test',
        'pruritu'
    ],
    'counts': [
        316, 313, 233, 225, 186, 185, 139, 134, 125, 119, 101, 99, 94, 90, 84, 84, 78, 76, 75, 69
    ]
}

COVID_df = pd.DataFrame(df_freq_symptoms_COVID_dict)

COVID_df.sort_values(by='counts', ascending=False, inplace=True)

# Creating the bar plot
plt.figure(figsize=(10, 6))
plt.barh(COVID_df['keys'], COVID_df['counts'], color='dodgerblue', alpha=0.7)
plt.xticks(rotation=90, fontsize=10)
plt.xlabel('Frequency')
plt.ylabel('Symptoms Commonly Reported Together')
plt.xlim(0, max(COVID_df['counts']) + 5)
plt.title('COVID-19 Symptom Frequency', fontsize = 30)
plt.grid(axis='y', alpha=0.7)
plt.tight_layout()

plt.show()

"""####MMR"""

import re
from nltk.stem import PorterStemmer

def process_symptoms(df):

    df['SYMPTOM1_processed'], df['SYMPTOM2_processed'], df['SYMPTOM3_processed'], df['SYMPTOM4_processed'], df['SYMPTOM5_processed'], df['all_symptoms_processed'] = "", "", "", "", "", ""

    # replace na
    df['SYMPTOM1'] = df['SYMPTOM1'].fillna("")
    df['SYMPTOM2'] = df['SYMPTOM2'].fillna("")
    df['SYMPTOM3'] = df['SYMPTOM3'].fillna("")
    df['SYMPTOM4'] = df['SYMPTOM4'].fillna("")
    df['SYMPTOM5'] = df['SYMPTOM5'].fillna("")

    # to lowercase
    symp_1 = [v.lower() for v in df['SYMPTOM1']]
    symp_2 = [v.lower() for v in df['SYMPTOM2']]
    symp_3 = [v.lower() for v in df['SYMPTOM3']]
    symp_4 = [v.lower() for v in df['SYMPTOM4']]
    symp_5 = [v.lower() for v in df['SYMPTOM5']]

    # remove any character other than alphabets and white spaces
    symp_1 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_1]
    symp_2 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_2]
    symp_3 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_3]
    symp_4 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_4]
    symp_5 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_5]

    # remove stopwords
    nltk.download("stopwords")
    stop_words = set(stopwords)
    symp_1 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_1]
    symp_2 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_2]
    symp_3 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_3]
    symp_4 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_4]
    symp_5 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_5]

    # word stemming
    ps = PorterStemmer()
    symp_1 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_1]
    symp_2 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_2]
    symp_3 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_3]
    symp_4 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_4]
    symp_5 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_5]

    # remove extra white spaces
    symp_1 = [re.sub(" +", " ", v) for v in symp_1]
    symp_2 = [re.sub(" +", " ", v) for v in symp_2]
    symp_3 = [re.sub(" +", " ", v) for v in symp_3]
    symp_4 = [re.sub(" +", " ", v) for v in symp_4]
    symp_5 = [re.sub(" +", " ", v) for v in symp_5]

    # save the preprocessed symptoms
    df['SYMPTOM1_processed'] = symp_1
    df['SYMPTOM2_processed'] = symp_2
    df['SYMPTOM3_processed'] = symp_3
    df['SYMPTOM4_processed'] = symp_4
    df['SYMPTOM5_processed'] = symp_5

    # concatenate the five columns of processed symptoms
    for i in range(0, df.shape[0]):
        if df["SYMPTOM1_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + df["SYMPTOM1_processed"].iloc[i]
        if df["SYMPTOM2_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM2_processed"].iloc[i]
        if df["SYMPTOM3_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM3_processed"].iloc[i]
        if df["SYMPTOM4_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM4_processed"].iloc[i]
        if df["SYMPTOM5_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM5_processed"].iloc[i]

    # remove extra white spaces and strip the final strings
    df["all_symptoms_processed"] = [re.sub(" +", " ", v) for v in df["all_symptoms_processed"]]
    df["all_symptoms_processed"] = [v.strip() for v in df["all_symptoms_processed"]]

    return df

#Then, call the function to process the symptoms:

MMR_PostCOVID_Data = process_symptoms(final_PostCOVID_pregnancyData_MMR)

# Filtering out keys that contain the specified substring. Need to remove Exposur Pregnanc
def remove_substring_from_dict(d, substring):
    return {key: value for key, value in d.items() if substring not in key}
# Creating word Clouds to see the most common words in the TDAP data
MMR_PostCOVID_WC = MMR_PostCOVID_Data['all_symptoms_processed'].value_counts().to_dict()
MMR_PostCOVID_WC = remove_substring_from_dict(MMR_PostCOVID_WC, "exposur pregnanc")
wc = WordCloud(width=800, height=400,background_color = "white").generate_from_frequencies(MMR_PostCOVID_WC)

# plot the WordCloud image
plt.figure(figsize = (10, 10), facecolor = None)
plt.imshow(wc)
plt.axis("off")
plt.title("MMR Post COVID-19 Symptom Word Cloud", fontsize = 30)
plt.show()

import collections
def get_most_frequent_values(list_of_values, n_most_frequent):
    counter_values = collections.Counter(list_of_values)
    most_common = counter_values.most_common(n_most_frequent) # most_common() produces k frequently encountered input values and their respective counts.
    counter_frequent_keys = [list(counter_values.most_common(n_most_frequent))[i][0] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    counter_frequent_counts = [list(counter_values.most_common(n_most_frequent))[i][1] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    # save in a data frame
    df = pd.DataFrame(columns = ["keys", "counts"])
    df["keys"] = counter_frequent_keys
    df["counts"] = counter_frequent_counts
    return df, counter_frequent_keys, counter_frequent_counts
n_most_frequent = 20
df_freq_symptoms_MMR_PC, freq_symptoms, freq_symptoms_count = get_most_frequent_values(MMR_PostCOVID_Data["all_symptoms_processed"], n_most_frequent)

df_freq_symptoms_MMR_PC

# Storing this in a dictionary is the best way to create a graph of the frequency distribution. Terms were copied directly from the list above.
df_freq_symptoms_MMR_PC_dict = {
    'keys': [
        'exposur pregnanc, advers event, pregnanc test...',
        'cataract congenit, cataract oper, eye disord...',
        'exposur pregnanc, advers event',
        'incorrect rout product administr, inject site...',
        'abort, addison diseas, amenorrhoea, cough, inf...',
        'rash',
        'pregnanc',
        'exposur pregnanc, rash',
        'advers event, ultrasound scan',
        'inappropri schedul product administr, advers e...',
        'pregnanc, pregnanc test posit',
        'exposur pregnanc',
        'accident exposur product, limb injuri, product...',
        'accident exposur product, advers event'
    ],
    'counts': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
}

MMR_PC_df = pd.DataFrame(df_freq_symptoms_MMR_PC_dict)

MMR_PC_df.sort_values(by='counts', ascending=False, inplace=True)

# Creating the bar plot
plt.figure(figsize=(10, 6))
plt.barh(MMR_PC_df['keys'], MMR_PC_df['counts'], color='dodgerblue')
plt.xlabel('Frequency')
plt.ylabel('Symptoms Commonly Reported Together')
plt.xlim(0, max(MMR_PC_df['counts']) + 5)
plt.title('MMR Post COVID-19 Symptom Frequency', fontsize = 30)
plt.tight_layout()

plt.show()

"""####HPV"""

import re
from nltk.stem import PorterStemmer

def process_symptoms(df):

    df['SYMPTOM1_processed'], df['SYMPTOM2_processed'], df['SYMPTOM3_processed'], df['SYMPTOM4_processed'], df['SYMPTOM5_processed'], df['all_symptoms_processed'] = "", "", "", "", "", ""

    # replace na
    df['SYMPTOM1'] = df['SYMPTOM1'].fillna("")
    df['SYMPTOM2'] = df['SYMPTOM2'].fillna("")
    df['SYMPTOM3'] = df['SYMPTOM3'].fillna("")
    df['SYMPTOM4'] = df['SYMPTOM4'].fillna("")
    df['SYMPTOM5'] = df['SYMPTOM5'].fillna("")

    # to lowercase
    symp_1 = [v.lower() for v in df['SYMPTOM1']]
    symp_2 = [v.lower() for v in df['SYMPTOM2']]
    symp_3 = [v.lower() for v in df['SYMPTOM3']]
    symp_4 = [v.lower() for v in df['SYMPTOM4']]
    symp_5 = [v.lower() for v in df['SYMPTOM5']]

    # remove any character other than alphabets and white spaces
    symp_1 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_1]
    symp_2 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_2]
    symp_3 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_3]
    symp_4 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_4]
    symp_5 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_5]

    # remove stopwords
    nltk.download("stopwords")
    stop_words = set(stopwords)
    symp_1 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_1]
    symp_2 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_2]
    symp_3 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_3]
    symp_4 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_4]
    symp_5 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_5]

    # word stemming
    ps = PorterStemmer()
    symp_1 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_1]
    symp_2 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_2]
    symp_3 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_3]
    symp_4 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_4]
    symp_5 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_5]

    # remove extra white spaces
    symp_1 = [re.sub(" +", " ", v) for v in symp_1]
    symp_2 = [re.sub(" +", " ", v) for v in symp_2]
    symp_3 = [re.sub(" +", " ", v) for v in symp_3]
    symp_4 = [re.sub(" +", " ", v) for v in symp_4]
    symp_5 = [re.sub(" +", " ", v) for v in symp_5]

    # save the preprocessed symptoms
    df['SYMPTOM1_processed'] = symp_1
    df['SYMPTOM2_processed'] = symp_2
    df['SYMPTOM3_processed'] = symp_3
    df['SYMPTOM4_processed'] = symp_4
    df['SYMPTOM5_processed'] = symp_5

    # concatenate the five columns of processed symptoms
    for i in range(0, df.shape[0]):
        if df["SYMPTOM1_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + df["SYMPTOM1_processed"].iloc[i]
        if df["SYMPTOM2_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM2_processed"].iloc[i]
        if df["SYMPTOM3_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM3_processed"].iloc[i]
        if df["SYMPTOM4_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM4_processed"].iloc[i]
        if df["SYMPTOM5_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM5_processed"].iloc[i]

    # remove extra white spaces and strip the final strings
    df["all_symptoms_processed"] = [re.sub(" +", " ", v) for v in df["all_symptoms_processed"]]
    df["all_symptoms_processed"] = [v.strip() for v in df["all_symptoms_processed"]]

    return df

#Then, call the function to process the symptoms:

HPV_PostCOVID_Data = process_symptoms(final_PostCOVID_pregnancyData_HPV)

# Filtering out keys that contain the specified substring. Need to remove Exposur Pregnanc
def remove_substring_from_dict(d, substring):
    return {key: value for key, value in d.items() if substring not in key}
# Creating word Clouds to see the most common words in the TDAP data
HPV_PostCOVID_WC = HPV_PostCOVID_Data['all_symptoms_processed'].value_counts().to_dict()
HPV_PostCOVID_WC = remove_substring_from_dict(HPV_PostCOVID_WC, "exposur pregnanc")
wc = WordCloud(width=800, height=400,background_color = "white").generate_from_frequencies(HPV_PostCOVID_WC)

# plot the WordCloud image
plt.figure(figsize = (10, 10), facecolor = None)
plt.imshow(wc)
plt.axis("off")
plt.title("HPV Post COVID-19 Symptom Word Cloud", fontsize = 30)
plt.show()

HPV_PostCOVID_Data

import collections
def get_most_frequent_values(list_of_values, n_most_frequent):
    counter_values = collections.Counter(list_of_values)
    most_common = counter_values.most_common(n_most_frequent) # most_common() produces k frequently encountered input values and their respective counts.
    counter_frequent_keys = [list(counter_values.most_common(n_most_frequent))[i][0] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    counter_frequent_counts = [list(counter_values.most_common(n_most_frequent))[i][1] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    # save in a data frame
    df = pd.DataFrame(columns = ["keys", "counts"])
    df["keys"] = counter_frequent_keys
    df["counts"] = counter_frequent_counts
    return df, counter_frequent_keys, counter_frequent_counts
n_most_frequent = 20
df_freq_symptoms_HPV_PC, freq_symptoms, freq_symptoms_count = get_most_frequent_values(HPV_PostCOVID_Data["all_symptoms_processed"], n_most_frequent)

df_freq_symptoms_HPV_PC

df_freq_symptoms_HPV_PC_dict = {
    'keys': [
        'exposur pregnanc',
        'exposur pregnanc, advers event',
        'diplegia, dizzi, fatigu, headach, hypersomnia',
        'abort spontan, alopecia, amenorrhoea, anti mue...',
        'chlamydia test, exposur pregnanc, gonorrhoea, ...',
        'abdomin pain, blood test abnorm, hormon level ...',
        'fatigu, impair work abil, somnol',
        'abdomin pain, amenorrhoea, autoimmun disord, a...',
        'pregnanc, pregnanc test neg, pregnanc test posit',
        'burn sensat, inject site pain, neuropathi peri...',
        'exposur pregnanc, advers event, pregnanc test ...',
        'abort spontan, adnexa uteri pain, alopecia, an...',
        'complic pregnanc',
        'infertil femal',
        'matern exposur pregnanc',
        'cervix carcinoma stage, confusion state, depre...',
        'matern exposur pregnanc, pregnanc test posit',
        'exposur pregnanc, human papilloma viru test po...',
        'colposcopi normal, papilloma viral infect, sme...',
        'abdomin pain'
    ],
    'counts': [12, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
}

HPV_PC_df = pd.DataFrame(df_freq_symptoms_HPV_PC_dict)

# Sort the DataFrame by counts in descending order for a better-looking plot
HPV_PC_df.sort_values(by='counts', ascending=False, inplace=True)

# Creating the bar plot
plt.figure(figsize=(10, 6))
plt.barh(HPV_PC_df['keys'], HPV_PC_df['counts'], color='dodgerblue')
plt.xlabel('Frequency')
plt.ylabel('Symptoms Commonly Reported Together')
plt.xlim(0, max(HPV_PC_df['counts']) + 5)
plt.title('HPV Post-COVID-19 Symptom Frequency', fontsize = 30)
plt.tight_layout()

plt.show()

"""#MBA"""

#%% Most Frequent Values in a List

def get_most_frequent_values(list_of_values, n_most_frequent):

    counter_values = collections.Counter(list_of_values)
    most_common = counter_values.most_common(n_most_frequent) # most_common() produces k frequently encountered input values and their respective counts.
    counter_frequent_keys = [list(counter_values.most_common(n_most_frequent))[i][0] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    counter_frequent_counts = [list(counter_values.most_common(n_most_frequent))[i][1] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]

    return counter_frequent_keys, counter_frequent_counts

#%% Association Rule Mining

def get_market_basket_analysis_results(list_elements, min_support, min_confidence, min_lift, min_length):

    association_results = list(apriori(list_elements, min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length))

    # save to data frame
    list_all_based_diagnosis = [''] * len(association_results)
    list_all_support = [0] * len(association_results)
    list_all_added_diagnosis = [''] * len(association_results)
    list_all_confidence = [0] * len(association_results)
    list_all_lift_diagnosis = [0] * len(association_results)

    for i in range(0, len(association_results)):
        # base diagnosis
        #list_all_based_diagnosis[i] = [v for v in association_results[i].ordered_statistics[0][0]][0]
        list_all_based_diagnosis[i] = [v for v in association_results[i].ordered_statistics[0].items_base]
        # support value
        list_all_support[i] = association_results[i].support
        # added diagnosis
        #list_all_added_diagnosis[i] = [v for v in association_results[i].ordered_statistics[0][1]][0]
        list_all_added_diagnosis[i] = [v for v in association_results[i].ordered_statistics[0].items_add]
        # confidence value
        list_all_confidence[i] = association_results[i].ordered_statistics[0][2]
        # lift value
        list_all_lift_diagnosis[i] = association_results[i].ordered_statistics[0][3]

    df_results_market_basket_analysis = pd.DataFrame(columns=['based symptom', 'support', 'added symptom', 'confidence', 'lift'])
    df_results_market_basket_analysis['based symptom'] = list_all_based_diagnosis
    df_results_market_basket_analysis['support'] = list_all_support
    df_results_market_basket_analysis['added symptom'] = list_all_added_diagnosis
    df_results_market_basket_analysis['confidence'] = list_all_confidence
    df_results_market_basket_analysis['lift'] = list_all_lift_diagnosis

    return df_results_market_basket_analysis

#%% Prepare Data for Market-Basket Analysis

def get_data_for_market_basket_analysis(df):

    df['symptoms_all'] = ""

    list_symptoms = []

    for i in range(0, df.shape[0]):
        symptoms = [df['SYMPTOM1'].iloc[i], df['SYMPTOM2'].iloc[i], df['SYMPTOM3'].iloc[i], df['SYMPTOM4'].iloc[i], df['SYMPTOM5'].iloc[i]]
        list_symptoms.append([v for v in symptoms if v!="" and v.lower()!='no adverse event'and v.lower()!= 'caesarean section' and v.lower()!= 'delivery' and v.lower()!= 'exposure during pregnancy'])

    df['symptoms_all'] = list_symptoms

    return df

"""#### TDAP Post COVID

- 0.7 and 0.8 for minimum confidence values
- 1.0 and 1.5 for minimum lift values
- used two different minimum lift values and minimum confidence values. This makes sure that all symptom associations that could be reported are
- support values were subject to change. Having a change in this parameter gave results that are relavant and otherwise wouldn't have been reported.
"""

# Symptoms for market-basket analysis
TDAP_PostCOVID_Data1 = get_data_for_market_basket_analysis(TDAP_PostCOVID_Data)


# set parameters
min_support = 0.01
min_confidence = 0.8
min_lift = 1.0
min_length = 2



TDAP_PostCOVID_Data1_MBAResults = get_market_basket_analysis_results(TDAP_PostCOVID_Data1['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(TDAP_PostCOVID_Data1_MBAResults['based symptom']) if v!=[]]
TDAP_PostCOVID_Data1_MBAResults = TDAP_PostCOVID_Data1_MBAResults.iloc[inds_inc, :].copy()
TDAP_PostCOVID_Data1_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/TDAP_PostCOVID_Data1_MBAResults.csv")

# Symptoms for market-basket analysis
TDAP_PostCOVID_Data2 = get_data_for_market_basket_analysis(TDAP_PostCOVID_Data)


# set parameters
min_support = 0.02
min_confidence = 0.7
min_lift = 1.5
min_length = 2



TDAP_PostCOVID_Data2_MBAResults = get_market_basket_analysis_results(TDAP_PostCOVID_Data2['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(TDAP_PostCOVID_Data2_MBAResults['based symptom']) if v!=[]]
TDAP_PostCOVID_Data2_MBAResults = TDAP_PostCOVID_Data2_MBAResults.iloc[inds_inc, :].copy()
TDAP_PostCOVID_Data2_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/TDAP_PostCOVID_Data2_MBAResults.csv")

pd.set_option('display.max_rows', None)

len(TDAP_PostCOVID_Data1_MBAResults)
len(TDAP_PostCOVID_Data2_MBAResults)

TDAP_PostCOVID_Data1_MBAResults.sort_values("lift")

#Saved the results into a csv to use for creating the graph. This was done because some of the results were very large and it wasn't practical. This was done for all results!
TDAP_PostCOVID_Data1_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/TDAP_PostCOVID_Data1_MBAResults.csv")
# Scatter plot with arrows
plt.figure(figsize=(10, 8))
plt.scatter(TDAP_PostCOVID_Data1_MBAResults['confidence'], TDAP_PostCOVID_Data1_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(TDAP_PostCOVID_Data1_MBAResults)):
    based_symptom = TDAP_PostCOVID_Data1_MBAResults['based symptom'][i]
    added_symptom = TDAP_PostCOVID_Data1_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(TDAP_PostCOVID_Data1_MBAResults['confidence'][i], TDAP_PostCOVID_Data1_MBAResults['lift'][i]),
                 xytext=(TDAP_PostCOVID_Data1_MBAResults['confidence'][i] + arrow_length, TDAP_PostCOVID_Data1_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('TDAP MBA 1 Post-COVID Results: Associations between Symptoms (Based on Confidence and Lift)', pad= 60, fontsize = 30)
plt.grid(True)
plt.show()

TDAP_PostCOVID_Data2_MBAResults.sort_values("lift")

TDAP_PostCOVID_Data2_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/TDAP_PostCOVID_Data2_MBAResults.csv")
# Scatter plot with arrows
plt.figure(figsize=(10, 8))
plt.scatter(TDAP_PostCOVID_Data2_MBAResults['confidence'], TDAP_PostCOVID_Data2_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(TDAP_PostCOVID_Data2_MBAResults)):
    based_symptom = TDAP_PostCOVID_Data2_MBAResults['based symptom'][i]
    added_symptom = TDAP_PostCOVID_Data2_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(TDAP_PostCOVID_Data2_MBAResults['confidence'][i], TDAP_PostCOVID_Data2_MBAResults['lift'][i]),
                 xytext=(TDAP_PostCOVID_Data2_MBAResults['confidence'][i] + arrow_length, TDAP_PostCOVID_Data2_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('TDAP MBA 2 Post-COVID Results: Associations between Symptoms (Based on Confidence and Lift)', pad = 40, fontsize = 30)
plt.grid(True)
plt.show()

"""#### MBA: Flu Vaccine"""

# Symptoms for market-basket analysis
FLU_PostCOVID_Data1 = get_data_for_market_basket_analysis(FLU_PostCOVID_Data)


# set parameters
min_support = 0.01
min_confidence = 0.8
min_lift = 1.0
min_length = 2



FLU_PostCOVID_Data1_MBAResults = get_market_basket_analysis_results(FLU_PostCOVID_Data1['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(FLU_PostCOVID_Data1_MBAResults['based symptom']) if v!=[]]
FLU_PostCOVID_Data1_MBAResults = FLU_PostCOVID_Data1_MBAResults.iloc[inds_inc, :].copy()
FLU_PostCOVID_Data1_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/FLU_PostCOVID_Data1_MBAResults.csv")

# Symptoms for market-basket analysis
FLU_PostCOVID_Data2 = get_data_for_market_basket_analysis(FLU_PostCOVID_Data)


# set parameters
min_support = 0.01
min_confidence = 0.7
min_lift = 1.5
min_length = 2



FLU_PostCOVID_Data2_MBAResults = get_market_basket_analysis_results(FLU_PostCOVID_Data2['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(FLU_PostCOVID_Data2_MBAResults['based symptom']) if v!=[]]
FLU_PostCOVID_Data2_MBAResults = FLU_PostCOVID_Data2_MBAResults.iloc[inds_inc, :].copy()
FLU_PostCOVID_Data2_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/FLU_PostCOVID_Data2_MBAResults.csv")

FLU_PostCOVID_Data1_MBAResults

FLU_PostCOVID_Data1_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/FLU_PostCOVID_Data1_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(8,6))
plt.scatter(FLU_PostCOVID_Data1_MBAResults['confidence'], FLU_PostCOVID_Data1_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(FLU_PostCOVID_Data1_MBAResults)):
    based_symptom = FLU_PostCOVID_Data1_MBAResults['based symptom'][i]
    added_symptom = FLU_PostCOVID_Data1_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(FLU_PostCOVID_Data1_MBAResults['confidence'][i], FLU_PostCOVID_Data1_MBAResults['lift'][i]),
                 xytext=(FLU_PostCOVID_Data1_MBAResults['confidence'][i] + arrow_length, FLU_PostCOVID_Data1_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))


# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('Inluenza MBA 1 Post-COVID Results: Associations between Symptoms (Based on Confidence and Lift)', pad = 40, fontsize = 30)
plt.grid(True)
plt.show()

FLU_PostCOVID_Data2_MBAResults

FLU_PostCOVID_Data2_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/FLU_PostCOVID_Data2_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(10,8))
plt.scatter(FLU_PostCOVID_Data2_MBAResults['confidence'], FLU_PostCOVID_Data2_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(FLU_PostCOVID_Data2_MBAResults)):
    based_symptom = FLU_PostCOVID_Data2_MBAResults['based symptom'][i]
    added_symptom = FLU_PostCOVID_Data2_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(FLU_PostCOVID_Data2_MBAResults['confidence'][i], FLU_PostCOVID_Data2_MBAResults['lift'][i]),
                 xytext=(FLU_PostCOVID_Data2_MBAResults['confidence'][i] + arrow_length, FLU_PostCOVID_Data2_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('Influenza MBA 2 Post-COVID Results: Associations between Symptoms (Based on Confidence and Lift)', pad = 40, fontsize = 30)
plt.grid(True)
plt.show()

"""####HEPA Vaccine"""

# Symptoms for market-basket analysis
HEPA_PostCOVID_Data1 = get_data_for_market_basket_analysis(HEPA_PostCOVID_Data)


# set parameters
min_support = 0.01
min_confidence = 0.8
min_lift = 1.0
min_length = 2



HEPA_PostCOVID_Data1_MBAResults = get_market_basket_analysis_results(HEPA_PostCOVID_Data1['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(HEPA_PostCOVID_Data1_MBAResults['based symptom']) if v!=[]]
HEPA_PostCOVID_Data1_MBAResults = HEPA_PostCOVID_Data1_MBAResults.iloc[inds_inc, :].copy()
HEPA_PostCOVID_Data1_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HEPA_PostCOVID_Data1_MBAResults.csv")

# Symptoms for market-basket analysis
HEPA_PostCOVID_Data2 = get_data_for_market_basket_analysis(HEPA_PostCOVID_Data)


# set parameters
min_support = 0.01
min_confidence = 0.7
min_lift = 1.5
min_length = 2



HEPA_PostCOVID_Data2_MBAResults = get_market_basket_analysis_results(HEPA_PostCOVID_Data2['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(HEPA_PostCOVID_Data2_MBAResults['based symptom']) if v!=[]]
HEPA_PostCOVID_Data2_MBAResults = HEPA_PostCOVID_Data2_MBAResults.iloc[inds_inc, :].copy()
HEPA_PostCOVID_Data2_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HEPA_PostCOVID_Data2_MBAResults.csv")

HEPA_PostCOVID_Data1_MBAResults.sort_values("lift")

HEPA_PostCOVID_Data1_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HEPA_PostCOVID_Data1_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(10,8))
plt.scatter(HEPA_PostCOVID_Data1_MBAResults['confidence'], HEPA_PostCOVID_Data1_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(HEPA_PostCOVID_Data1_MBAResults)):
    plt.annotate(HEPA_PostCOVID_Data1_MBAResults['added symptom'][i], xy=(HEPA_PostCOVID_Data1_MBAResults['confidence'][i], HEPA_PostCOVID_Data1_MBAResults['lift'][i]),
                 xytext=(HEPA_PostCOVID_Data1_MBAResults['confidence'][i] + arrow_length, HEPA_PostCOVID_Data1_MBAResults['lift'][i] + arrow_length),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('Hepatitis A MBA 1 Post-COVID Results: Associations between Symptoms (Based on Confidence and Lift)',pad = 40, fontsize = 30)
plt.grid(True)
plt.show()

HEPA_PostCOVID_Data2_MBAResults.sort_values("lift")

HEPA_PreCOVID_Data_2_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HEPA_PostCOVID_Data2_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(10,8))
plt.scatter(HEPA_PreCOVID_Data_2_MBAResults['confidence'], HEPA_PreCOVID_Data_2_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(HEPA_PreCOVID_Data_2_MBAResults)):
    plt.annotate(HEPA_PreCOVID_Data_2_MBAResults['added symptom'][i], xy=(HEPA_PreCOVID_Data_2_MBAResults['confidence'][i], HEPA_PreCOVID_Data_2_MBAResults['lift'][i]),
                 xytext=(HEPA_PreCOVID_Data_2_MBAResults['confidence'][i] + arrow_length, HEPA_PreCOVID_Data_2_MBAResults['lift'][i] + arrow_length),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('Hepatitis A MBA 2 Post-COVID Results: Associations between Symptoms (Based on Confidence and Lift)', pad = 30, fontsize = 30)
plt.grid(True)
plt.show()

"""####HEP B MBA"""

# Symptoms for market-basket analysis
HEPB_PostCOVID_Data1 = get_data_for_market_basket_analysis(HEPB_PostCOVID_Data)


# set parameters
min_support = 0.01
min_confidence = 0.8
min_lift = 1.0
min_length = 2



HEPB_PostCOVID_Data1_MBAResults = get_market_basket_analysis_results(HEPB_PostCOVID_Data1['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(HEPA_PostCOVID_Data1_MBAResults['based symptom']) if v!=[]]
HEPB_PostCOVID_Data1_MBAResults = HEPB_PostCOVID_Data1_MBAResults.iloc[inds_inc, :].copy()
HEPB_PostCOVID_Data1_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HEPB_PostCOVID_Data1_MBAResults.csv")

# Symptoms for market-basket analysis
HEPB_PostCOVID_Data2 = get_data_for_market_basket_analysis(HEPB_PostCOVID_Data)


# set parameters
min_support = 0.01
min_confidence = 0.7
min_lift = 1.5
min_length = 2



HEPB_PostCOVID_Data2_MBAResults = get_market_basket_analysis_results(HEPB_PostCOVID_Data2['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(HEPB_PostCOVID_Data2_MBAResults['based symptom']) if v!=[]]
HEPB_PostCOVID_Data2_MBAResults = HEPB_PostCOVID_Data2_MBAResults.iloc[inds_inc, :].copy()
HEPB_PostCOVID_Data2_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HEPB_PostCOVID_Data2_MBAResults.csv")

HEPB_PostCOVID_Data1_MBAResults.sort_values("lift")

HEPB_PostCOVID_Data1_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HEPB_PostCOVID_Data1_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(10,8))
plt.scatter(HEPB_PostCOVID_Data1_MBAResults['confidence'], HEPB_PostCOVID_Data1_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(HEPB_PostCOVID_Data1_MBAResults)):
    based_symptom = HEPB_PostCOVID_Data1_MBAResults['based symptom'][i]
    added_symptom = HEPB_PostCOVID_Data1_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(HEPB_PostCOVID_Data1_MBAResults['confidence'][i], HEPB_PostCOVID_Data1_MBAResults['lift'][i]),
                 xytext=(HEPB_PostCOVID_Data1_MBAResults['confidence'][i] + arrow_length, HEPB_PostCOVID_Data1_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('Hepatitis B MBA 1 Post-COVID Results: Associations between Symptoms (Based on Confidence and Lift)', pad=40, fontsize = 30)
plt.grid(True)
plt.show()

HEPB_PostCOVID_Data2_MBAResults.sort_values("lift")

HEPB_PostCOVID_Data2_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HEPB_PostCOVID_Data2_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(8, 6))
plt.scatter(HEPB_PostCOVID_Data2_MBAResults['confidence'], HEPB_PostCOVID_Data2_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(HEPB_PostCOVID_Data2_MBAResults)):
    based_symptom = HEPB_PostCOVID_Data2_MBAResults['based symptom'][i]
    added_symptom = HEPB_PostCOVID_Data2_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(HEPB_PostCOVID_Data2_MBAResults['confidence'][i], HEPB_PostCOVID_Data2_MBAResults['lift'][i]),
                 xytext=(HEPB_PostCOVID_Data2_MBAResults['confidence'][i] + arrow_length, HEPB_PostCOVID_Data2_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('Hepatitis B MBA 2 Post-COVID Results: Associations between Symptoms (Based on Confidence and Lift)', pad=30, fontsize = 30)
plt.grid(True)
plt.show()

"""####COVID"""

# Symptoms for market-basket analysis
COVID_Data1 = get_data_for_market_basket_analysis(COVID_Data)


# set parameters
min_support = 0.001
min_confidence = 0.8
min_lift = 1.0
min_length = 2



COVID_Data1_MBAResults = get_market_basket_analysis_results(COVID_Data1['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(COVID_Data1_MBAResults['based symptom']) if v!=[]]
COVID_Data1_MBAResults = COVID_Data1_MBAResults.iloc[inds_inc, :].copy()
COVID_Data1_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/COVID_Data1_MBAResults.csv")

# Symptoms for market-basket analysis
COVID_Data2 = get_data_for_market_basket_analysis(COVID_Data)


# set parameters
min_support = 0.001
min_confidence = 0.7
min_lift = 1.5
min_length = 2



COVID_Data2_MBAResults = get_market_basket_analysis_results(COVID_Data2['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(COVID_Data2_MBAResults['based symptom']) if v!=[]]
COVID_Data2_MBAResults = COVID_Data2_MBAResults.iloc[inds_inc, :].copy()
COVID_Data2_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/COVID_Data2_MBAResults.csv")

COVID_Data1_MBAResults.sort_values("lift")

COVID_Data1_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/COVID_Data1_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(8, 6))
plt.scatter(COVID_Data1_MBAResults['confidence'], COVID_Data1_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(COVID_Data1_MBAResults)):
    based_symptom = COVID_Data1_MBAResults['based symptom'][i]
    added_symptom = COVID_Data1_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(COVID_Data1_MBAResults['confidence'][i], COVID_Data1_MBAResults['lift'][i]),
                 xytext=(COVID_Data1_MBAResults['confidence'][i] + arrow_length, COVID_Data1_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('COVID-19 MBA 1 Results: Associations between Symptoms (Based on Confidence and Lift)', pad=30, fontsize = 30)
plt.grid(True)
plt.show()

COVID_Data2_MBAResults.sort_values("lift")

len(COVID_Data1_MBAResults)

len(COVID_Data2_MBAResults)

COVID_Data2_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/COVID_Data2_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(10,8))
plt.scatter(COVID_Data2_MBAResults['confidence'], COVID_Data2_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(COVID_Data2_MBAResults)):
    based_symptom = COVID_Data2_MBAResults['based symptom'][i]
    added_symptom = COVID_Data2_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(COVID_Data2_MBAResults['confidence'][i], COVID_Data2_MBAResults['lift'][i]),
                 xytext=(COVID_Data2_MBAResults['confidence'][i] + arrow_length, COVID_Data2_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('COVID-19 MBA 2 Results: Associations between Symptoms (Based on Confidence and Lift)', pad=40, fontsize = 30)
plt.grid(True)
plt.show()

"""####MMR"""

# Symptoms for market-basket analysis
MMR_PostCOVID_Data1 = get_data_for_market_basket_analysis(MMR_PostCOVID_Data)


# set parameters
min_support = 0.01
min_confidence = 0.8
min_lift = 1.0
min_length = 2



MMR_PostCOVID_Data1_MBAResults = get_market_basket_analysis_results(MMR_PostCOVID_Data1['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(MMR_PostCOVID_Data1_MBAResults['based symptom']) if v!=[]]
MMR_PostCOVID_Data1_MBAResults = MMR_PostCOVID_Data1_MBAResults.iloc[inds_inc, :].copy()
MMR_PostCOVID_Data1_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/MMR_PostCOVID_Data1_MBAResults.csv")

# Symptoms for market-basket analysis
MMR_PostCOVID_Data2 = get_data_for_market_basket_analysis(MMR_PostCOVID_Data)


# set parameters
min_support = 0.01
min_confidence = 0.7
min_lift = 1.5
min_length = 2



MMR_PostCOVID_Data2_MBAResults = get_market_basket_analysis_results(MMR_PostCOVID_Data2['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(MMR_PostCOVID_Data2_MBAResults['based symptom']) if v!=[]]
MMR_PostCOVID_Data2_MBAResults = MMR_PostCOVID_Data2_MBAResults.iloc[inds_inc, :].copy()
MMR_PostCOVID_Data2_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/MMR_PostCOVID_Data2_MBAResults.csv")

MMR_PostCOVID_Data1_MBAResults.sort_values("lift")

len(MMR_PostCOVID_Data1_MBAResults)

len(MMR_PostCOVID_Data2_MBAResults)

MMR_PostCOVID_Data1_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/MMR_PostCOVID_Data1_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(8, 6))
plt.scatter(MMR_PostCOVID_Data1_MBAResults['confidence'], MMR_PostCOVID_Data1_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(MMR_PostCOVID_Data1_MBAResults)):
    based_symptom = MMR_PostCOVID_Data1_MBAResults['based symptom'][i]
    added_symptom = MMR_PostCOVID_Data1_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(MMR_PostCOVID_Data1_MBAResults['confidence'][i], MMR_PostCOVID_Data1_MBAResults['lift'][i]),
                 xytext=(MMR_PostCOVID_Data1_MBAResults['confidence'][i] + arrow_length, MMR_PostCOVID_Data1_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('MMR Post-COVID19 MBA 1 Results: Associations between Symptoms (Based on Confidence and Lift)', pad=30, fontsize = 30)
plt.grid(True)
plt.show()

MMR_PostCOVID_Data2_MBAResults.sort_values('lift')

MMR_PostCOVID_Data2_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/MMR_PostCOVID_Data2_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(8, 6))
plt.scatter(MMR_PostCOVID_Data2_MBAResults['confidence'], MMR_PostCOVID_Data2_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(MMR_PostCOVID_Data2_MBAResults)):
    based_symptom = MMR_PostCOVID_Data2_MBAResults['based symptom'][i]
    added_symptom = MMR_PostCOVID_Data2_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(MMR_PostCOVID_Data2_MBAResults['confidence'][i], MMR_PostCOVID_Data2_MBAResults['lift'][i]),
                 xytext=(MMR_PostCOVID_Data2_MBAResults['confidence'][i] + arrow_length, MMR_PostCOVID_Data2_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('MMR MBA 2 Post- COVID Results: Associations between Symptoms (Based on Confidence and Lift)', pad=60, fontsize = 30)
plt.grid(True)
plt.show()

"""#### HPV"""

# Symptoms for market-basket analysis
HPV_PostCOVID_Data1 = get_data_for_market_basket_analysis(HPV_PostCOVID_Data)


# set parameters
min_support = 0.01
min_confidence = 0.8
min_lift = 1.0
min_length = 2



HPV_PostCOVID_Data1_MBAResults = get_market_basket_analysis_results(HPV_PostCOVID_Data1['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(HPV_PostCOVID_Data1_MBAResults['based symptom']) if v!=[]]
HPV_PostCOVID_Data1_MBAResults = HPV_PostCOVID_Data1_MBAResults.iloc[inds_inc, :].copy()
HPV_PostCOVID_Data1_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HPV_PostCOVID_Data1_MBAResults.csv")

# Symptoms for market-basket analysis
HPV_PostCOVID_Data2 = get_data_for_market_basket_analysis(HPV_PostCOVID_Data)


# set parameters
min_support = 0.01
min_confidence = 0.7
min_lift = 1.5
min_length = 2



HPV_PostCOVID_Data2_MBAResults = get_market_basket_analysis_results(HPV_PostCOVID_Data2['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(HPV_PostCOVID_Data2_MBAResults['based symptom']) if v!=[]]
HPV_PostCOVID_Data2_MBAResults = HPV_PostCOVID_Data2_MBAResults.iloc[inds_inc, :].copy()
HPV_PostCOVID_Data2_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HPV_PostCOVID_Data2_MBAResults.csv")

pd.set_option("display_max.rows", None)

HPV_PostCOVID_Data1_MBAResults.sort_values("lift")

HPV_PreCOVID_Data_1_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HPV_PostCOVID_Data1_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(10,8))
plt.scatter(HPV_PreCOVID_Data_1_MBAResults['confidence'], HPV_PreCOVID_Data_1_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(HPV_PreCOVID_Data_1_MBAResults)):
    based_symptom = HPV_PreCOVID_Data_1_MBAResults['based symptom'][i]
    added_symptom = HPV_PreCOVID_Data_1_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(HPV_PreCOVID_Data_1_MBAResults['confidence'][i], HPV_PreCOVID_Data_1_MBAResults['lift'][i]),
                 xytext=(HPV_PreCOVID_Data_1_MBAResults['confidence'][i] + arrow_length, HPV_PreCOVID_Data_1_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('HPV MBA 1 Post- COVID Results: Associations between Symptoms (Based on Confidence and Lift)', pad=60, fontsize= 30)
plt.grid(True)
plt.show()

HPV_PostCOVID_Data2_MBAResults.sort_values("lift")

len(HPV_PostCOVID_Data2_MBAResults)

HPV_PostCOVID_Data2_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HPV_PostCOVID_Data2_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(10,8))
plt.scatter(HPV_PostCOVID_Data2_MBAResults['confidence'], HPV_PostCOVID_Data2_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(HPV_PostCOVID_Data2_MBAResults)):
    based_symptom = HPV_PostCOVID_Data2_MBAResults['based symptom'][i]
    added_symptom = HPV_PostCOVID_Data2_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(HPV_PostCOVID_Data2_MBAResults['confidence'][i], HPV_PostCOVID_Data2_MBAResults['lift'][i]),
                 xytext=(HPV_PostCOVID_Data2_MBAResults['confidence'][i] + arrow_length, HPV_PostCOVID_Data2_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('HPV MBA 2 Post- COVID Results:Associations between Symptoms (Based on Confidence and Lift)', pad=60, fontsize=30)
plt.grid(True)
plt.show()