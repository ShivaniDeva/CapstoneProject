# -*- coding: utf-8 -*-
"""HIDS510_VAERSPreCOVIDAnalysis_ShivaniD_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cD4gpSoHnyHcKBgdBVEigR1bwff1jYVJ

# Main Objectives of Project

This project in its entierty aims to support the public health initative of educating pregnant women on what vaccines to take during their pregnancy to accomodate vaccination schedules. Using the Vaccine Adverse Events Reporting System (VAERS) Data set as the sole source of Data for adverse events, the unsupervised Leaning Method of Market Basket Analysis to see the associations between commonly reported symptoms in their magnitude and frequency. The Vaccines we have looked for is TDAP, Influenza, Hepatitis A, Hepatitis B, MMR, and HPV.

#Imports
"""

import pandas as pd
import numpy as np
from collections import Counter
import nltk
nltk.download('punkt')
from nltk.tokenize import sent_tokenize
from nltk.tokenize import word_tokenize
from nltk.probability import FreqDist
import matplotlib.pyplot as plt
import string
string.punctuation
from nltk.corpus import stopwords
nltk.download('stopwords')
stopwords = stopwords.words("english")
import sys
import sklearn
!pip install apyori
from apyori import apriori
from wordcloud import WordCloud

"""#Reading in the Data"""

#Reading in 2016
vaers2016_data = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/InputFiles/2016VAERSData/2016VAERSDATA.csv", encoding='cp1252')
vaers2016_symptoms = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/InputFiles/2016VAERSData/2016VAERSSYMPTOMS.csv")
vaers2016_vacc = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/InputFiles/2016VAERSData/2016VAERSVAX.csv")

#Reading in 2017
vaers2017_data = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/InputFiles/2017VAERSData/2017VAERSDATA.csv", encoding='cp1252')
vaers2017_symptoms = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/InputFiles/2017VAERSData/2017VAERSSYMPTOMS.csv")
vaers2017_vacc = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/InputFiles/2017VAERSData/2017VAERSVAX.csv", encoding='cp1252')

#Reading in 2018
vaers2018_data = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/InputFiles/2018VAERSData/2018VAERSDATA.csv", encoding='cp1252')
vaers2018_symptoms = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/InputFiles/2018VAERSData/2018VAERSSYMPTOMS.csv")
vaers2018_vacc = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/InputFiles/2018VAERSData/2018VAERSVAX.csv")

#Reading in 2019
vaers2019_data = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/InputFiles/2019VAERSData/2019VAERSDATA.csv", encoding='cp1252')
vaers2019_symptoms = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/InputFiles/2019VAERSData/2019VAERSSYMPTOMS.csv")
vaers2019_vacc = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/InputFiles/2019VAERSData/2019VAERSVAX.csv", encoding='cp1252')

"""#Combining the Data
There are 3 steps to this part of combining the data. The first step includes amalgamating all of the years of data by their respective file formats. 3 separate data frames are created which contain the data (free text), symptoms, and vaccinations for the patients. From there using the data files I filtered down by sex == F. The pregnancy data was a combination of the cleaned vaers data but used two different columns and contatiated that. Then I combined the pregnancy data and the vaccines and symptoms data and dropped unnecessary columns.
"""

vaers_data = pd.concat([vaers2016_data, vaers2017_data, vaers2018_data, vaers2019_data]).drop_duplicates('VAERS_ID').fillna("")
vaers_symptoms = pd.concat([vaers2016_symptoms, vaers2017_symptoms, vaers2018_symptoms, vaers2019_symptoms]).drop_duplicates('VAERS_ID').fillna("")
vaers_vacc = pd.concat([vaers2016_vacc, vaers2017_vacc, vaers2018_vacc, vaers2019_vacc]).drop_duplicates('VAERS_ID').fillna("")

vaers_data_cleaned =  vaers_data[(vaers_data["SEX"]== "F") | (vaers_data["SEX"]== "f")].copy().fillna("")

pregnancy_data1 = vaers_data_cleaned[vaers_data_cleaned['SYMPTOM_TEXT'].str.contains('preg')].copy()
pregnancy_data2= vaers_data_cleaned[vaers_data_cleaned['CUR_ILL'].str.contains('preg')].copy()

combined_pregnancy_data = pd.concat([pregnancy_data1,pregnancy_data2]).drop_duplicates('VAERS_ID').fillna("")

combined_pregnancy_data_cleaned = combined_pregnancy_data.drop(columns = ['STATE', 'AGE_YRS', 'CAGE_YR', 'CAGE_MO', 'SEX',
       'RPT_DATE', 'DIED', 'DATEDIED', 'L_THREAT', 'ER_VISIT',
       'HOSPITAL', 'HOSPDAYS', 'X_STAY', 'DISABLE', 'RECOVD', 'VAX_DATE',
       'ONSET_DATE', 'NUMDAYS', 'LAB_DATA', 'V_ADMINBY', 'V_FUNDBY',
       'OTHER_MEDS', 'HISTORY', 'PRIOR_VAX', 'SPLTTYPE',
       'FORM_VERS', 'TODAYS_DATE', 'BIRTH_DEFECT', 'OFC_VISIT', 'ER_ED_VISIT'])

combined_pregnancy_data_cleaned

vaers_symp_vacc = pd.merge(vaers_symptoms,vaers_vacc, on= "VAERS_ID").drop_duplicates('VAERS_ID').fillna("")
pre_covid_data = pd.merge(vaers_data_cleaned,vaers_symp_vacc,on= "VAERS_ID").drop_duplicates('VAERS_ID').fillna("")

cleaned_pre_covid_data = pre_covid_data.drop(columns= ['STATE','CAGE_YR', 'CAGE_MO', 'SEX',
       'RPT_DATE', 'SYMPTOM_TEXT', 'DIED', 'DATEDIED', 'L_THREAT', 'ER_VISIT',
       'HOSPITAL', 'HOSPDAYS', 'X_STAY', 'DISABLE', 'RECOVD', 'VAX_DATE',
       'ONSET_DATE', 'NUMDAYS', 'LAB_DATA', 'V_ADMINBY', 'V_FUNDBY',
       'OTHER_MEDS', 'CUR_ILL', 'HISTORY', 'PRIOR_VAX', 'SPLTTYPE',
       'FORM_VERS', 'TODAYS_DATE', 'BIRTH_DEFECT', 'OFC_VISIT', 'ER_ED_VISIT',
       'ALLERGIES', 'SYMPTOMVERSION1','SYMPTOMVERSION2','SYMPTOMVERSION3','SYMPTOMVERSION4','SYMPTOMVERSION5'])

cleaned_pre_covid_data

final_Precovid_pregnancyData = pd.merge(cleaned_pre_covid_data,combined_pregnancy_data_cleaned,on= "VAERS_ID").drop_duplicates('VAERS_ID').fillna("")

final_Precovid_pregnancyData

"""### For individual vaccines: Searching through the dataframes"""

final_Precovid_pregnancyData_TDAP = final_Precovid_pregnancyData[(final_Precovid_pregnancyData['VAX_NAME'].str.contains('TDAP'))].copy()

final_Precovid_pregnancyData_TDAP

final_Precovid_pregnancyData_FLU = final_Precovid_pregnancyData[(final_Precovid_pregnancyData['VAX_NAME'].str.contains('FLU'))].copy()

final_Precovid_pregnancyData_FLU

final_Precovid_pregnancyData_HEPA = final_Precovid_pregnancyData[(final_Precovid_pregnancyData['VAX_NAME'].str.contains('HEP A'))].copy()

final_Precovid_pregnancyData_HEPA

len(final_Precovid_pregnancyData_HEPA)

final_Precovid_pregnancyData_HEPB = final_Precovid_pregnancyData[(final_Precovid_pregnancyData['VAX_NAME'].str.contains('HEP B'))].copy()

final_Precovid_pregnancyData_HEPB

len(final_Precovid_pregnancyData_HEPB)

final_Precovid_pregnancyData_MMR = final_Precovid_pregnancyData[(final_Precovid_pregnancyData['VAX_NAME'].str.contains('MMR'))].copy()

final_Precovid_pregnancyData_MMR

final_Precovid_pregnancyData_HPV = final_Precovid_pregnancyData[(final_Precovid_pregnancyData['VAX_NAME'].str.contains('HPV'))].copy()

final_Precovid_pregnancyData_HPV

"""#NLP & Frequency Distrubutions

#### TDAP Vaccine
"""

import re
from nltk.stem import PorterStemmer

def process_symptoms(df):

    df['SYMPTOM1_processed'], df['SYMPTOM2_processed'], df['SYMPTOM3_processed'], df['SYMPTOM4_processed'], df['SYMPTOM5_processed'], df['all_symptoms_processed'] = "", "", "", "", "", ""

    # replace na
    df['SYMPTOM1'] = df['SYMPTOM1'].fillna("")
    df['SYMPTOM2'] = df['SYMPTOM2'].fillna("")
    df['SYMPTOM3'] = df['SYMPTOM3'].fillna("")
    df['SYMPTOM4'] = df['SYMPTOM4'].fillna("")
    df['SYMPTOM5'] = df['SYMPTOM5'].fillna("")

    # to lowercase
    symp_1 = [v.lower() for v in df['SYMPTOM1']]
    symp_2 = [v.lower() for v in df['SYMPTOM2']]
    symp_3 = [v.lower() for v in df['SYMPTOM3']]
    symp_4 = [v.lower() for v in df['SYMPTOM4']]
    symp_5 = [v.lower() for v in df['SYMPTOM5']]

    # remove any character other than alphabets and white spaces
    symp_1 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_1]
    symp_2 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_2]
    symp_3 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_3]
    symp_4 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_4]
    symp_5 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_5]

    # remove stopwords
    nltk.download("stopwords")
    stop_words = set(stopwords)
    symp_1 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_1]
    symp_2 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_2]
    symp_3 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_3]
    symp_4 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_4]
    symp_5 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_5]

    # word stemming
    ps = PorterStemmer()
    symp_1 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_1]
    symp_2 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_2]
    symp_3 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_3]
    symp_4 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_4]
    symp_5 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_5]

    # remove extra white spaces
    symp_1 = [re.sub(" +", " ", v) for v in symp_1]
    symp_2 = [re.sub(" +", " ", v) for v in symp_2]
    symp_3 = [re.sub(" +", " ", v) for v in symp_3]
    symp_4 = [re.sub(" +", " ", v) for v in symp_4]
    symp_5 = [re.sub(" +", " ", v) for v in symp_5]

    # save the preprocessed symptoms
    df['SYMPTOM1_processed'] = symp_1
    df['SYMPTOM2_processed'] = symp_2
    df['SYMPTOM3_processed'] = symp_3
    df['SYMPTOM4_processed'] = symp_4
    df['SYMPTOM5_processed'] = symp_5

    # concatenate the five columns of processed symptoms
    for i in range(0, df.shape[0]):
        if df["SYMPTOM1_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + df["SYMPTOM1_processed"].iloc[i]
        if df["SYMPTOM2_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM2_processed"].iloc[i]
        if df["SYMPTOM3_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM3_processed"].iloc[i]
        if df["SYMPTOM4_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM4_processed"].iloc[i]
        if df["SYMPTOM5_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM5_processed"].iloc[i]

    # remove extra white spaces and strip the final strings
    df["all_symptoms_processed"] = [re.sub(" +", " ", v) for v in df["all_symptoms_processed"]]
    df["all_symptoms_processed"] = [v.strip() for v in df["all_symptoms_processed"]]

    return df

#Then, call the function to process the symptoms:

TDAP_PreCOVID_Data = process_symptoms(final_Precovid_pregnancyData_TDAP)

TDAP_PreCOVID_Data

# Filtering out keys that contain the specified substring. Need to remove Exposur Pregnanc
def remove_substring_from_dict(d, substring):
    return {key: value for key, value in d.items() if substring not in key}

# Creating word Clouds to see the most common words in the TDAP data
tdap_WC = TDAP_PreCOVID_Data['all_symptoms_processed'].value_counts().to_dict()
tdap_WC = remove_substring_from_dict(tdap_WC, "exposur pregnanc")
wc = WordCloud(width=800, height=400,background_color = "white").generate_from_frequencies(tdap_WC)

# Plotting the WordCloud image
plt.figure(figsize = (10, 10), facecolor = None)
plt.imshow(wc)
plt.axis("off")
plt.title("TDAP Pre-COVID-19 Symptom Word Cloud", fontsize = 30)
plt.show()

# Getting Frequencies of Symptoms
import collections
def get_most_frequent_values(list_of_values, n_most_frequent):
    counter_values = collections.Counter(list_of_values)
    most_common = counter_values.most_common(n_most_frequent) # most_common() produces k frequently encountered input values and their respective counts.
    counter_frequent_keys = [list(counter_values.most_common(n_most_frequent))[i][0] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    counter_frequent_counts = [list(counter_values.most_common(n_most_frequent))[i][1] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    # save in a data frame
    df = pd.DataFrame(columns = ["keys", "counts"])
    df["keys"] = counter_frequent_keys
    df["counts"] = counter_frequent_counts
    return df, counter_frequent_keys, counter_frequent_counts
n_most_frequent = 20
df_freq_symptoms_TDAP, freq_symptoms, freq_symptoms_count = get_most_frequent_values(TDAP_PreCOVID_Data["all_symptoms_processed"], n_most_frequent)

df_freq_symptoms_TDAP

# Storing this in a dictionary is the best way to create a graph of the frequency distribution. Terms were copied directly from the list above.
df_freq_symptoms_TDAP_dict = {
    'keys': ['exposur pregnanc', 'exposur pregnanc, advers event', 'exposur pregnanc, advers event, product storag...',
             'exposur pregnanc, extra dose administ', 'exposur pregnanc, product storag error',
             'exposur pregnanc, advers event, wrong drug adm...', 'exposur pregnanc, pain extrem',
             'exposur pregnanc, foetal death, stillbirth', 'exposur pregnanc, stillbirth',
             'exposur pregnanc, extra dose administ, advers ...', 'exposur pregnanc, ultrasound antenat screen no...',
             'alpha foetoprotein normal, exposur pregnanc, p...', 'exposur pregnanc, inject site bruis, inject si...',
             'exposur pregnanc, preterm prematur ruptur membran', 'blood test, exposur pregnanc, gynaecolog examin',
             'arthralgia, exposur pregnanc, hallucin, pyrexi...', 'back pain, csf protein increas, csf white bloo...',
             'alpha foetoprotein, cytogenet analysi abnorm, ...', 'erythema, exposur pregnanc, feel hot, pyrexia,...',
             'joint swell, nausea, pain, peripher swell, vomit'],
    'counts': [27, 13, 5, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1]
}

df_TDAP_graph = pd.DataFrame(df_freq_symptoms_TDAP_dict)

df_TDAP_graph = df_TDAP_graph.sort_values(by='counts', ascending=False)

# Creating the bar chart
plt.figure(figsize=(12, 6))
plt.barh(df_TDAP_graph['keys'], df_TDAP_graph['counts'], color='dodgerblue')
plt.xticks(rotation=90, ha='right', fontsize='small')
plt.xlabel('Frequency')
plt.ylabel('Symptoms Commonly Reported Together')
plt.title('TDAP Pre-COVID-19 Frequency', fontsize=30)
plt.xlim(0, max(df_TDAP_graph['counts']) + 5)
plt.tight_layout()
plt.show()

"""####Flu Vaccine"""

import re
from nltk.stem import PorterStemmer

def process_symptoms(df):

    df['SYMPTOM1_processed'], df['SYMPTOM2_processed'], df['SYMPTOM3_processed'], df['SYMPTOM4_processed'], df['SYMPTOM5_processed'], df['all_symptoms_processed'] = "", "", "", "", "", ""

    # replace na
    df['SYMPTOM1'] = df['SYMPTOM1'].fillna("")
    df['SYMPTOM2'] = df['SYMPTOM2'].fillna("")
    df['SYMPTOM3'] = df['SYMPTOM3'].fillna("")
    df['SYMPTOM4'] = df['SYMPTOM4'].fillna("")
    df['SYMPTOM5'] = df['SYMPTOM5'].fillna("")

    # to lowercase
    symp_1 = [v.lower() for v in df['SYMPTOM1']]
    symp_2 = [v.lower() for v in df['SYMPTOM2']]
    symp_3 = [v.lower() for v in df['SYMPTOM3']]
    symp_4 = [v.lower() for v in df['SYMPTOM4']]
    symp_5 = [v.lower() for v in df['SYMPTOM5']]

    # remove any character other than alphabets and white spaces
    symp_1 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_1]
    symp_2 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_2]
    symp_3 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_3]
    symp_4 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_4]
    symp_5 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_5]

    # remove stopwords
    nltk.download("stopwords")
    stop_words = set(stopwords)
    symp_1 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_1]
    symp_2 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_2]
    symp_3 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_3]
    symp_4 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_4]
    symp_5 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_5]

    # word stemming
    ps = PorterStemmer()
    symp_1 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_1]
    symp_2 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_2]
    symp_3 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_3]
    symp_4 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_4]
    symp_5 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_5]

    # remove extra white spaces
    symp_1 = [re.sub(" +", " ", v) for v in symp_1]
    symp_2 = [re.sub(" +", " ", v) for v in symp_2]
    symp_3 = [re.sub(" +", " ", v) for v in symp_3]
    symp_4 = [re.sub(" +", " ", v) for v in symp_4]
    symp_5 = [re.sub(" +", " ", v) for v in symp_5]

    # save the preprocessed symptoms
    df['SYMPTOM1_processed'] = symp_1
    df['SYMPTOM2_processed'] = symp_2
    df['SYMPTOM3_processed'] = symp_3
    df['SYMPTOM4_processed'] = symp_4
    df['SYMPTOM5_processed'] = symp_5

    # concatenate the five columns of processed symptoms
    for i in range(0, df.shape[0]):
        if df["SYMPTOM1_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + df["SYMPTOM1_processed"].iloc[i]
        if df["SYMPTOM2_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM2_processed"].iloc[i]
        if df["SYMPTOM3_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM3_processed"].iloc[i]
        if df["SYMPTOM4_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM4_processed"].iloc[i]
        if df["SYMPTOM5_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM5_processed"].iloc[i]

    # remove extra white spaces and strip the final strings
    df["all_symptoms_processed"] = [re.sub(" +", " ", v) for v in df["all_symptoms_processed"]]
    df["all_symptoms_processed"] = [v.strip() for v in df["all_symptoms_processed"]]

    return df

#Then, call the function to process the symptoms:

FLU_PreCOVID_Data = process_symptoms(final_Precovid_pregnancyData_FLU)

FLU_PreCOVID_Data

# Filtering out keys that contain the specified substring. Need to remove Exposur Pregnanc
def remove_substring_from_dict(d, substring):
    return {key: value for key, value in d.items() if substring not in key}
# Creating word Clouds to see the most common words in the Flu data
flu_WC = FLU_PreCOVID_Data['all_symptoms_processed'].value_counts().to_dict()
flu_WC = remove_substring_from_dict(tdap_WC, "exposur pregnanc")
wc = WordCloud(width=800, height=400,background_color = "white").generate_from_frequencies(flu_WC)

# plot the WordCloud image
plt.figure(figsize = (10, 10), facecolor = None)
plt.imshow(wc)
plt.axis("off")
plt.title("Influenza Symptoms Pre-COVID-19 Word Cloud", fontsize= 30)
plt.show()

# Getting Frequencies of Symptoms
import collections
def get_most_frequent_values(list_of_values, n_most_frequent):
    counter_values = collections.Counter(list_of_values)
    most_common = counter_values.most_common(n_most_frequent) # most_common() produces k frequently encountered input values and their respective counts.
    counter_frequent_keys = [list(counter_values.most_common(n_most_frequent))[i][0] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    counter_frequent_counts = [list(counter_values.most_common(n_most_frequent))[i][1] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    # save in a data frame
    df = pd.DataFrame(columns = ["keys", "counts"])
    df["keys"] = counter_frequent_keys
    df["counts"] = counter_frequent_counts
    return df, counter_frequent_keys, counter_frequent_counts
n_most_frequent = 20
df_freq_symptoms_FLU, freq_symptoms, freq_symptoms_count = get_most_frequent_values(FLU_PreCOVID_Data["all_symptoms_processed"], n_most_frequent)

df_freq_symptoms_FLU

# Storing this in a dictionary is the best way to create a graph of the frequency distribution. Terms were copied directly from the list above.
df_freq_symptoms_FLU_dict = {
    'keys': ['exposur pregnanc', 'exposur pregnanc, advers event', 'exposur pregnanc, advers event, prenat screen ...',
             'abort spontan, exposur pregnanc', 'expir product administ, advers event',
             'expir product administ, exposur pregnanc, adve...', 'menstruat delay, pregnanc test neg',
             'apgar score normal, foetal exposur pregnanc, l...', 'exposur pregnanc, advers event, wrong product ...',
             'exposur pregnanc, advers event, wrong drug adm...', 'expir product administ, exposur pregnanc',
             'exposur pregnanc, product storag error', 'apgar score normal, caesarean section, foetal ...',
             'abort spontan, exposur pregnanc, ultrasound an...', 'exposur pregnanc, wrong drug administ',
             'caesarean section, exposur pregnanc',
             'exposur pregnanc, pregnanc test urin posit, ul...', 'incorrect dose administ, advers event',
             'matern exposur pregnanc, advers event', 'exposur pregnanc, foetal death, stillbirth'],
    'counts': [70, 50, 11, 9, 5, 5, 4, 4, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2]
}

df_FLU_graph = pd.DataFrame(df_freq_symptoms_FLU_dict)

df_FLU_graph = df_FLU_graph.sort_values(by='counts', ascending=False)

# Creating the bar chart
plt.figure(figsize=(12, 6))
plt.barh(df_FLU_graph['keys'], df_FLU_graph['counts'], color='dodgerblue')
plt.xticks(rotation=90, ha='right', fontsize='small')
plt.xlabel('Frequency')
plt.ylabel('Symptoms Commonly Reported Together')
plt.xlim(0, max(df_FLU_graph['counts']) + 5)
plt.title('Inluenza Pre-COVID-19 Symptom Frequency', fontsize=40)
plt.tight_layout()
plt.show()

"""####Hepatitis A Vaccine"""

import re
from nltk.stem import PorterStemmer

def process_symptoms(df):

    df['SYMPTOM1_processed'], df['SYMPTOM2_processed'], df['SYMPTOM3_processed'], df['SYMPTOM4_processed'], df['SYMPTOM5_processed'], df['all_symptoms_processed'] = "", "", "", "", "", ""

    # replace na
    df['SYMPTOM1'] = df['SYMPTOM1'].fillna("")
    df['SYMPTOM2'] = df['SYMPTOM2'].fillna("")
    df['SYMPTOM3'] = df['SYMPTOM3'].fillna("")
    df['SYMPTOM4'] = df['SYMPTOM4'].fillna("")
    df['SYMPTOM5'] = df['SYMPTOM5'].fillna("")

    # to lowercase
    symp_1 = [v.lower() for v in df['SYMPTOM1']]
    symp_2 = [v.lower() for v in df['SYMPTOM2']]
    symp_3 = [v.lower() for v in df['SYMPTOM3']]
    symp_4 = [v.lower() for v in df['SYMPTOM4']]
    symp_5 = [v.lower() for v in df['SYMPTOM5']]

    # remove any character other than alphabets and white spaces
    symp_1 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_1]
    symp_2 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_2]
    symp_3 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_3]
    symp_4 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_4]
    symp_5 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_5]

    # remove stopwords
    nltk.download("stopwords")
    stop_words = set(stopwords)
    symp_1 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_1]
    symp_2 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_2]
    symp_3 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_3]
    symp_4 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_4]
    symp_5 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_5]

    # word stemming
    ps = PorterStemmer()
    symp_1 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_1]
    symp_2 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_2]
    symp_3 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_3]
    symp_4 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_4]
    symp_5 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_5]

    # remove extra white spaces
    symp_1 = [re.sub(" +", " ", v) for v in symp_1]
    symp_2 = [re.sub(" +", " ", v) for v in symp_2]
    symp_3 = [re.sub(" +", " ", v) for v in symp_3]
    symp_4 = [re.sub(" +", " ", v) for v in symp_4]
    symp_5 = [re.sub(" +", " ", v) for v in symp_5]

    # save the preprocessed symptoms
    df['SYMPTOM1_processed'] = symp_1
    df['SYMPTOM2_processed'] = symp_2
    df['SYMPTOM3_processed'] = symp_3
    df['SYMPTOM4_processed'] = symp_4
    df['SYMPTOM5_processed'] = symp_5

    # concatenate the five columns of processed symptoms
    for i in range(0, df.shape[0]):
        if df["SYMPTOM1_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + df["SYMPTOM1_processed"].iloc[i]
        if df["SYMPTOM2_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM2_processed"].iloc[i]
        if df["SYMPTOM3_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM3_processed"].iloc[i]
        if df["SYMPTOM4_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM4_processed"].iloc[i]
        if df["SYMPTOM5_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM5_processed"].iloc[i]

    # remove extra white spaces and strip the final strings
    df["all_symptoms_processed"] = [re.sub(" +", " ", v) for v in df["all_symptoms_processed"]]
    df["all_symptoms_processed"] = [v.strip() for v in df["all_symptoms_processed"]]

    return df

#Then, call the function to process the symptoms:

HEPA_PreCOVID_Data = process_symptoms(final_Precovid_pregnancyData_HEPA)

HEPA_PreCOVID_Data

# Filtering out keys that contain the specified substring. Need to remove Exposur Pregnanc
def remove_substring_from_dict(d, substring):
    return {key: value for key, value in d.items() if substring not in key}
# Creating word Clouds to see the most common words in the Hep A data
HepA_WC = HEPA_PreCOVID_Data['all_symptoms_processed'].value_counts().to_dict()
HepA_WC = remove_substring_from_dict(tdap_WC, "exposur pregnanc")
wc = WordCloud(width=800, height=400,background_color = "white").generate_from_frequencies(HepA_WC)

# Plotting the WordCloud image
plt.figure(figsize = (10, 10), facecolor = None)
plt.imshow(wc)
plt.axis("off")
plt.title("Hepatitis A Symptoms Pre-COVID-19 Word Cloud", fontsize = 30)
plt.show()

# Getting Frequencies of Symptoms
import collections
def get_most_frequent_values(list_of_values, n_most_frequent):
    counter_values = collections.Counter(list_of_values)
    most_common = counter_values.most_common(n_most_frequent) # most_common() produces k frequently encountered input values and their respective counts.
    counter_frequent_keys = [list(counter_values.most_common(n_most_frequent))[i][0] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    counter_frequent_counts = [list(counter_values.most_common(n_most_frequent))[i][1] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    # save in a data frame
    df = pd.DataFrame(columns = ["keys", "counts"])
    df["keys"] = counter_frequent_keys
    df["counts"] = counter_frequent_counts
    return df, counter_frequent_keys, counter_frequent_counts
n_most_frequent = 20
df_freq_symptoms_HEPA, freq_symptoms, freq_symptoms_count = get_most_frequent_values(HEPA_PreCOVID_Data["all_symptoms_processed"], n_most_frequent)

df_freq_symptoms_HEPA

# Storing this in a dictionary is the best way to create a graph of the frequency distribution. Terms were copied directly from the list above.
df_freq_symptoms_HEPA_dict = {
    'keys': ['exposur pregnanc', 'exposur pregnanc, advers event', 'syncop',
             'exposur pregnanc, advers event, pregnanc test ...', 'dizzi, electrocardiogram normal, syncop',
             'skin mass', 'inject site discolour, inject site erythema, i...',
             'abort spontan, matern exposur pregnanc, tuberc...', 'exposur pregnanc, underdos',
             'dysphonia, oropharyng pain, paraesthesia, prur...', 'hyperaesthesia, rash erythemat, skin warm, urt...',
             'asthenia, dizzi, dyspnoea, exposur pregnanc, n...', 'exposur pregnanc, inject site pain',
             'mump, parot, rubulaviru test posit', 'advers event, product administ patient inappro...'],
    'counts': [3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
}

df_HEPA_graph = pd.DataFrame(df_freq_symptoms_HEPA_dict)

df_HEPA_graph = df_HEPA_graph.sort_values(by='counts', ascending=False)

# Creating the bar chart
plt.figure(figsize=(12, 6))
plt.barh(df_HEPA_graph['keys'], df_HEPA_graph['counts'], color='dodgerblue')
plt.xticks(rotation=90, ha='right', fontsize='small')
plt.xlabel('Frequency')
plt.ylabel('Symptoms Commonly Reported Together')
plt.xlim(0, max(df_HEPA_graph['counts']) + 5)
plt.title('Hep A Pre-COVID-19 Symptom Frequency', fontsize = 30)
plt.tight_layout()
plt.show()

"""####Hepatitis B Vaccine"""

import re
from nltk.stem import PorterStemmer

def process_symptoms(df):

    df['SYMPTOM1_processed'], df['SYMPTOM2_processed'], df['SYMPTOM3_processed'], df['SYMPTOM4_processed'], df['SYMPTOM5_processed'], df['all_symptoms_processed'] = "", "", "", "", "", ""

    # replace na
    df['SYMPTOM1'] = df['SYMPTOM1'].fillna("")
    df['SYMPTOM2'] = df['SYMPTOM2'].fillna("")
    df['SYMPTOM3'] = df['SYMPTOM3'].fillna("")
    df['SYMPTOM4'] = df['SYMPTOM4'].fillna("")
    df['SYMPTOM5'] = df['SYMPTOM5'].fillna("")

    # to lowercase
    symp_1 = [v.lower() for v in df['SYMPTOM1']]
    symp_2 = [v.lower() for v in df['SYMPTOM2']]
    symp_3 = [v.lower() for v in df['SYMPTOM3']]
    symp_4 = [v.lower() for v in df['SYMPTOM4']]
    symp_5 = [v.lower() for v in df['SYMPTOM5']]

    # remove any character other than alphabets and white spaces
    symp_1 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_1]
    symp_2 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_2]
    symp_3 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_3]
    symp_4 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_4]
    symp_5 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_5]

    # remove stopwords
    nltk.download("stopwords")
    stop_words = set(stopwords)
    symp_1 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_1]
    symp_2 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_2]
    symp_3 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_3]
    symp_4 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_4]
    symp_5 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_5]

    # word stemming
    ps = PorterStemmer()
    symp_1 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_1]
    symp_2 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_2]
    symp_3 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_3]
    symp_4 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_4]
    symp_5 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_5]

    # remove extra white spaces
    symp_1 = [re.sub(" +", " ", v) for v in symp_1]
    symp_2 = [re.sub(" +", " ", v) for v in symp_2]
    symp_3 = [re.sub(" +", " ", v) for v in symp_3]
    symp_4 = [re.sub(" +", " ", v) for v in symp_4]
    symp_5 = [re.sub(" +", " ", v) for v in symp_5]

    # save the preprocessed symptoms
    df['SYMPTOM1_processed'] = symp_1
    df['SYMPTOM2_processed'] = symp_2
    df['SYMPTOM3_processed'] = symp_3
    df['SYMPTOM4_processed'] = symp_4
    df['SYMPTOM5_processed'] = symp_5

    # concatenate the five columns of processed symptoms
    for i in range(0, df.shape[0]):
        if df["SYMPTOM1_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + df["SYMPTOM1_processed"].iloc[i]
        if df["SYMPTOM2_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM2_processed"].iloc[i]
        if df["SYMPTOM3_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM3_processed"].iloc[i]
        if df["SYMPTOM4_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM4_processed"].iloc[i]
        if df["SYMPTOM5_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM5_processed"].iloc[i]

    # remove extra white spaces and strip the final strings
    df["all_symptoms_processed"] = [re.sub(" +", " ", v) for v in df["all_symptoms_processed"]]
    df["all_symptoms_processed"] = [v.strip() for v in df["all_symptoms_processed"]]

    return df

#Then, call the function to process the symptoms:

HEPB_PreCOVID_Data = process_symptoms(final_Precovid_pregnancyData_HEPB)

HEPB_PreCOVID_Data

# Filtering out keys that contain the specified substring. Need to remove Exposur Pregnanc
def remove_substring_from_dict(d, substring):
    return {key: value for key, value in d.items() if substring not in key}
# Creating word Clouds to see the most common words in the HepB data
HepB_WC = HEPB_PreCOVID_Data['all_symptoms_processed'].value_counts().to_dict()
HepB_WC = remove_substring_from_dict(tdap_WC, "exposur pregnanc")
wc = WordCloud(width=800, height=400,background_color = "white").generate_from_frequencies(HepB_WC)

# plot the WordCloud image
plt.figure(figsize = (10, 10), facecolor = None)
plt.imshow(wc)
plt.axis("off")
plt.title("Hepatitis B Symptoms Pre-COVID-19 Word Cloud", fontsize = 30)
plt.show()

# Getting Frequencies of Symptoms
import collections
def get_most_frequent_values(list_of_values, n_most_frequent):
    counter_values = collections.Counter(list_of_values)
    most_common = counter_values.most_common(n_most_frequent) # most_common() produces k frequently encountered input values and their respective counts.
    counter_frequent_keys = [list(counter_values.most_common(n_most_frequent))[i][0] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    counter_frequent_counts = [list(counter_values.most_common(n_most_frequent))[i][1] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    # save in a data frame
    df = pd.DataFrame(columns = ["keys", "counts"])
    df["keys"] = counter_frequent_keys
    df["counts"] = counter_frequent_counts
    return df, counter_frequent_keys, counter_frequent_counts
n_most_frequent = 20
df_freq_symptoms_HEPB, freq_symptoms, freq_symptoms_count = get_most_frequent_values(HEPB_PreCOVID_Data["all_symptoms_processed"], n_most_frequent)

df_freq_symptoms_HEPB

# Storing this in a dictionary is the best way to create a graph of the frequency distribution. Terms were copied directly from the list above.
df_freq_symptoms_HEPB_dict = {
    'keys': ['exposur pregnanc', 'hepat b antibodi neg', 'abort spontan, exposur pregnanc',
             'exposur pregnanc, stillbirth', 'amniot caviti infect, deliveri, exposur pregnanc',
             'exposur pregnanc, advers event', 'hepat b surfac antibodi neg, inappropri schedu...',
             'apgar score normal, atrial septal defect, card...', 'hepat b antibodi neg, hepat b test neg',
             'dizzi, hyperhidrosi, hyperreflexia, loss consc...', 'dizzi, electrocardiogram normal, fatigu, labor...',
             'abort spontan, drug administ patient inappropr...', 'chest discomfort, cough, dyspnoea, exposur pre...',
             'abdomin distens, abdomin pain, acut kidney inj...', 'diarrhoea, pruritu, rash, respiratori disord, ...',
             'caesarean section, hepat b, hepat b dna increa...', 'hepat b antibodi neg, inappropri schedul drug ...',
             'exposur pregnanc, human chorion gonadotropin i...', 'hepat b surfac antigen neg',
             'headach, nausea, vomit'],
    'counts': [5, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
}

df_HEPB_graph = pd.DataFrame(df_freq_symptoms_HEPB_dict)

df_HEPB_graph = df_HEPB_graph.sort_values(by='counts', ascending=False)

# Creating the bar chart
plt.figure(figsize=(12, 6))
plt.barh(df_HEPB_graph['keys'], df_HEPB_graph['counts'], color='dodgerblue')
plt.xticks(rotation=90, ha='right', fontsize='small')
plt.xlabel('Frequency')
plt.ylabel('Symptoms Commonly Reported Together')
plt.xlim(0, max(df_HEPB_graph['counts']) + 5)
plt.title('Hep B Pre-COVID-19 Symptom Frequency', fontsize = 30)
plt.tight_layout()
plt.show()

"""####MMR"""

import re
from nltk.stem import PorterStemmer

def process_symptoms(df):

    df['SYMPTOM1_processed'], df['SYMPTOM2_processed'], df['SYMPTOM3_processed'], df['SYMPTOM4_processed'], df['SYMPTOM5_processed'], df['all_symptoms_processed'] = "", "", "", "", "", ""

    # replace na
    df['SYMPTOM1'] = df['SYMPTOM1'].fillna("")
    df['SYMPTOM2'] = df['SYMPTOM2'].fillna("")
    df['SYMPTOM3'] = df['SYMPTOM3'].fillna("")
    df['SYMPTOM4'] = df['SYMPTOM4'].fillna("")
    df['SYMPTOM5'] = df['SYMPTOM5'].fillna("")

    # to lowercase
    symp_1 = [v.lower() for v in df['SYMPTOM1']]
    symp_2 = [v.lower() for v in df['SYMPTOM2']]
    symp_3 = [v.lower() for v in df['SYMPTOM3']]
    symp_4 = [v.lower() for v in df['SYMPTOM4']]
    symp_5 = [v.lower() for v in df['SYMPTOM5']]

    # remove any character other than alphabets and white spaces
    symp_1 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_1]
    symp_2 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_2]
    symp_3 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_3]
    symp_4 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_4]
    symp_5 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_5]

    # remove stopwords
    nltk.download("stopwords")
    stop_words = set(stopwords)
    symp_1 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_1]
    symp_2 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_2]
    symp_3 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_3]
    symp_4 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_4]
    symp_5 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_5]

    # word stemming
    ps = PorterStemmer()
    symp_1 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_1]
    symp_2 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_2]
    symp_3 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_3]
    symp_4 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_4]
    symp_5 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_5]

    # remove extra white spaces
    symp_1 = [re.sub(" +", " ", v) for v in symp_1]
    symp_2 = [re.sub(" +", " ", v) for v in symp_2]
    symp_3 = [re.sub(" +", " ", v) for v in symp_3]
    symp_4 = [re.sub(" +", " ", v) for v in symp_4]
    symp_5 = [re.sub(" +", " ", v) for v in symp_5]

    # save the preprocessed symptoms
    df['SYMPTOM1_processed'] = symp_1
    df['SYMPTOM2_processed'] = symp_2
    df['SYMPTOM3_processed'] = symp_3
    df['SYMPTOM4_processed'] = symp_4
    df['SYMPTOM5_processed'] = symp_5

    # concatenate the five columns of processed symptoms
    for i in range(0, df.shape[0]):
        if df["SYMPTOM1_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + df["SYMPTOM1_processed"].iloc[i]
        if df["SYMPTOM2_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM2_processed"].iloc[i]
        if df["SYMPTOM3_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM3_processed"].iloc[i]
        if df["SYMPTOM4_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM4_processed"].iloc[i]
        if df["SYMPTOM5_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM5_processed"].iloc[i]

    # remove extra white spaces and strip the final strings
    df["all_symptoms_processed"] = [re.sub(" +", " ", v) for v in df["all_symptoms_processed"]]
    df["all_symptoms_processed"] = [v.strip() for v in df["all_symptoms_processed"]]

    return df

#Then, call the function to process the symptoms:

MMR_PreCOVID_Data = process_symptoms(final_Precovid_pregnancyData_MMR)

MMR_PreCOVID_Data

# Filtering out keys that contain the specified substring. Need to remove Exposur Pregnanc
def remove_substring_from_dict(d, substring):
    return {key: value for key, value in d.items() if substring not in key}
# Creating word Clouds to see the most common words in the MMR data
MMR_WC = MMR_PreCOVID_Data['all_symptoms_processed'].value_counts().to_dict()
MMR_WC = remove_substring_from_dict(tdap_WC, "exposur pregnanc")
wc = WordCloud(width=800, height=400,background_color = "white").generate_from_frequencies(MMR_WC)

#plotting the WordCloud image
plt.figure(figsize = (10, 10), facecolor = None)
plt.imshow(wc)
plt.axis("off")
plt.title("MMR Symptoms Pre-COVID-19 Word Cloud", fontsize = 30)
plt.show()

# Getting Frequencies of Symptoms
import collections
def get_most_frequent_values(list_of_values, n_most_frequent):
    counter_values = collections.Counter(list_of_values)
    most_common = counter_values.most_common(n_most_frequent) # most_common() produces k frequently encountered input values and their respective counts.
    counter_frequent_keys = [list(counter_values.most_common(n_most_frequent))[i][0] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    counter_frequent_counts = [list(counter_values.most_common(n_most_frequent))[i][1] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    # save in a data frame
    df = pd.DataFrame(columns = ["keys", "counts"])
    df["keys"] = counter_frequent_keys
    df["counts"] = counter_frequent_counts
    return df, counter_frequent_keys, counter_frequent_counts
n_most_frequent = 20
df_freq_symptoms_MMR, freq_symptoms, freq_symptoms_count = get_most_frequent_values(MMR_PreCOVID_Data["all_symptoms_processed"], n_most_frequent)

df_freq_symptoms_MMR

# Storing this in a dictionary is the best way to create a graph of the frequency distribution. Terms were copied directly from the list above.
df_freq_symptoms_MMR_dict = {
    'keys': ['exposur pregnanc', 'exposur pregnanc, advers event', 'exposur pregnanc, pregnanc test posit',
             'measl antibodi neg, mump antibodi test neg, rubella antibodi test neg',
             'measl antibodi neg', 'exposur pregnanc, pregnanc test urin posit',
             'exposur pregnanc, advers event, pregnanc test ...',
             'inject site erythema, inject site warmth', 'matern exposur pregnanc',
             'matern exposur pregnanc, rubella antibodi neg', 'rubella antibodi neg',
             'exposur pregnanc, human chorion gonadotropin posit, pregnanc test urin posit',
             'antibodi test neg',
             'measl antibodi neg, mump antibodi test posit, rubella antibodi test neg',
             'dizzi, exposur pregnanc, inject site pain, pregnanc test urin posit',
             'blood pressur decreas, exposur pregnanc, nausea, paraesthesia, pyrexi',
             'exposur pregnanc, inappropri schedul drug administr, product storag error',
             'exposur pregnanc, wrong drug administr', 'blood test, exposur pregnanc, pregnanc test urin posit',
             'exposur pregnanc, extra dose administr, measl antibodi posit, mump antibodi neg, rubella antibodi neg'],
    'counts': [14, 13, 4, 4, 4, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1]
}

df_MMR_graph = pd.DataFrame(df_freq_symptoms_MMR_dict)

df_MMR_graph = df_MMR_graph.sort_values(by='counts', ascending=False)

# Creating the bar chart
plt.figure(figsize=(8,6))
plt.barh(df_MMR_graph['keys'], df_MMR_graph['counts'], color='dodgerblue')
plt.xticks(rotation=90, ha='right', fontsize='small')
plt.xlabel('Frequency')
plt.ylabel('Symptoms Commonly Reported Together')
plt.xlim(0, max(df_MMR_graph['counts']) + 5)
plt.title('MMR Pre-COVID-19 Symptom Frequency', fontsize = 30)
plt.show()

"""#### HPV"""

import re
from nltk.stem import PorterStemmer

def process_symptoms(df):

    df['SYMPTOM1_processed'], df['SYMPTOM2_processed'], df['SYMPTOM3_processed'], df['SYMPTOM4_processed'], df['SYMPTOM5_processed'], df['all_symptoms_processed'] = "", "", "", "", "", ""

    # replace na
    df['SYMPTOM1'] = df['SYMPTOM1'].fillna("")
    df['SYMPTOM2'] = df['SYMPTOM2'].fillna("")
    df['SYMPTOM3'] = df['SYMPTOM3'].fillna("")
    df['SYMPTOM4'] = df['SYMPTOM4'].fillna("")
    df['SYMPTOM5'] = df['SYMPTOM5'].fillna("")

    # to lowercase
    symp_1 = [v.lower() for v in df['SYMPTOM1']]
    symp_2 = [v.lower() for v in df['SYMPTOM2']]
    symp_3 = [v.lower() for v in df['SYMPTOM3']]
    symp_4 = [v.lower() for v in df['SYMPTOM4']]
    symp_5 = [v.lower() for v in df['SYMPTOM5']]

    # remove any character other than alphabets and white spaces
    symp_1 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_1]
    symp_2 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_2]
    symp_3 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_3]
    symp_4 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_4]
    symp_5 = [re.sub(r'[^a-z\s.]', ' ', v) for v in symp_5]

    # remove stopwords
    nltk.download("stopwords")
    stop_words = set(stopwords)
    symp_1 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_1]
    symp_2 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_2]
    symp_3 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_3]
    symp_4 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_4]
    symp_5 = [' '.join([word for word in v.split() if word not in stop_words]).strip() for v in symp_5]

    # word stemming
    ps = PorterStemmer()
    symp_1 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_1]
    symp_2 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_2]
    symp_3 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_3]
    symp_4 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_4]
    symp_5 = [' '.join([ps.stem(word) for word in v.split()]).strip() for v in symp_5]

    # remove extra white spaces
    symp_1 = [re.sub(" +", " ", v) for v in symp_1]
    symp_2 = [re.sub(" +", " ", v) for v in symp_2]
    symp_3 = [re.sub(" +", " ", v) for v in symp_3]
    symp_4 = [re.sub(" +", " ", v) for v in symp_4]
    symp_5 = [re.sub(" +", " ", v) for v in symp_5]

    # save the preprocessed symptoms
    df['SYMPTOM1_processed'] = symp_1
    df['SYMPTOM2_processed'] = symp_2
    df['SYMPTOM3_processed'] = symp_3
    df['SYMPTOM4_processed'] = symp_4
    df['SYMPTOM5_processed'] = symp_5

    # concatenate the five columns of processed symptoms
    for i in range(0, df.shape[0]):
        if df["SYMPTOM1_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + df["SYMPTOM1_processed"].iloc[i]
        if df["SYMPTOM2_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM2_processed"].iloc[i]
        if df["SYMPTOM3_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM3_processed"].iloc[i]
        if df["SYMPTOM4_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM4_processed"].iloc[i]
        if df["SYMPTOM5_processed"].iloc[i] != "":
            df["all_symptoms_processed"].iloc[i] = df["all_symptoms_processed"].iloc[i] + ", " + df["SYMPTOM5_processed"].iloc[i]

    # remove extra white spaces and strip the final strings
    df["all_symptoms_processed"] = [re.sub(" +", " ", v) for v in df["all_symptoms_processed"]]
    df["all_symptoms_processed"] = [v.strip() for v in df["all_symptoms_processed"]]

    return df

#Then, call the function to process the symptoms:

HPV_PreCOVID_Data = process_symptoms(final_Precovid_pregnancyData_HPV)

HPV_PreCOVID_Data

# Filtering out keys that contain the specified substring. Need to remove Exposur Pregnanc
def remove_substring_from_dict(d, substring):
    return {key: value for key, value in d.items() if substring not in key}
# Creating word Clouds to see the most common words in the HPV data
HPV_WC = HPV_PreCOVID_Data['all_symptoms_processed'].value_counts().to_dict()
HPV_WC = remove_substring_from_dict(tdap_WC, "exposur pregnanc")
wc = WordCloud(width=800, height=400,background_color = "white").generate_from_frequencies(HPV_WC)

# plotting the WordCloud image
plt.figure(figsize = (10, 10), facecolor = None)
plt.imshow(wc)
plt.axis("off")
plt.title("HPV Symptoms Pre-COVID-19 Word Cloud", fontsize = 30)
plt.show()

# Getting Frequencies of Symptoms
import collections
def get_most_frequent_values(list_of_values, n_most_frequent):
    counter_values = collections.Counter(list_of_values)
    most_common = counter_values.most_common(n_most_frequent) # most_common() produces k frequently encountered input values and their respective counts.
    counter_frequent_keys = [list(counter_values.most_common(n_most_frequent))[i][0] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    counter_frequent_counts = [list(counter_values.most_common(n_most_frequent))[i][1] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    # save in a data frame
    df = pd.DataFrame(columns = ["keys", "counts"])
    df["keys"] = counter_frequent_keys
    df["counts"] = counter_frequent_counts
    return df, counter_frequent_keys, counter_frequent_counts
n_most_frequent = 20
df_freq_symptoms_HPV, freq_symptoms, freq_symptoms_count = get_most_frequent_values(HPV_PreCOVID_Data["all_symptoms_processed"], n_most_frequent)

df_freq_symptoms_HPV

# Storing this in a dictionary is the best way to create a graph of the frequency distribution. Terms were copied directly from the list above.
df_freq_symptoms_HPV_dict = {
    'keys': ['exposur pregnanc, advers event', 'exposur pregnanc', 'exposur pregnanc, pregnanc test posit',
             'exposur pregnanc, advers event, pregnanc test', 'matern exposur pregnanc',
             'exposur pregnanc, pregnanc test urin posit', 'urticaria',
             'exposur pregnanc, advers event, wrong drug adm', 'exposur pregnanc, wrong product administ',
             'exposur pregnanc, advers event, wrong product', 'pyrexia',
             'human papilloma viru test posit, papilloma', 'exposur pregnanc, ultrasound antenat screen',
             'exposur pregnanc, inject site pain', 'rash generalis', 'exposur pregnanc, malais',
             'pain extrem', 'extra dose administ, advers event', 'peripher swell',
             'exposur pregnanc, interchang vaccin product,'],
    'counts': [49, 41, 17, 12, 11, 8, 7, 6, 6, 5, 4, 3, 3, 2, 2, 2, 2, 2, 2, 2]
}

df_HPV_graph = pd.DataFrame(df_freq_symptoms_HPV_dict)

df_HPV_graph = df_HPV_graph.sort_values(by='counts', ascending=False)

# Creating the bar chart
plt.figure(figsize=(12, 6))
plt.barh(df_HPV_graph['keys'], df_HPV_graph['counts'], color='dodgerblue')
plt.xticks(rotation=90, ha='right', fontsize='small')
plt.xlabel('Frequency')
plt.ylabel('Symptoms Commonly Reported Together')
plt.xlim(0, max(df_HPV_graph['counts']) + 5)
plt.title('HPV Pre-COVID19 Symptom Frequency', fontsize = 30)
plt.tight_layout()
plt.show()

"""#Market Basket Analysis"""

#%% Most Frequent Values in a List
def get_most_frequent_values(list_of_values, n_most_frequent):
    counter_values = collections.Counter(list_of_values)
    most_common = counter_values.most_common(n_most_frequent) # most_common() produces k frequently encountered input values and their respective counts.
    counter_frequent_keys = [list(counter_values.most_common(n_most_frequent))[i][0] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    counter_frequent_counts = [list(counter_values.most_common(n_most_frequent))[i][1] for i in range(0, len(list(counter_values.most_common(n_most_frequent))))]
    return counter_frequent_keys, counter_frequent_counts

#%% Association Rule Mining
def get_market_basket_analysis_results(list_elements, min_support, min_confidence, min_lift, min_length):
    association_results = list(apriori(list_elements, min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length))
    # save to data frame
    list_all_based_diagnosis = [''] * len(association_results)
    list_all_support = [0] * len(association_results)
    list_all_added_diagnosis = [''] * len(association_results)
    list_all_confidence = [0] * len(association_results)
    list_all_lift_diagnosis = [0] * len(association_results)
    for i in range(0, len(association_results)):
        # base diagnosis
        #list_all_based_diagnosis[i] = [v for v in association_results[i].ordered_statistics[0][0]][0]
        list_all_based_diagnosis[i] = [v for v in association_results[i].ordered_statistics[0].items_base]
        # support value
        list_all_support[i] = association_results[i].support
        # added diagnosis
        #list_all_added_diagnosis[i] = [v for v in association_results[i].ordered_statistics[0][1]][0]
        list_all_added_diagnosis[i] = [v for v in association_results[i].ordered_statistics[0].items_add]
        # confidence value
        list_all_confidence[i] = association_results[i].ordered_statistics[0][2]
        # lift value
        list_all_lift_diagnosis[i] = association_results[i].ordered_statistics[0][3]
    df_results_market_basket_analysis = pd.DataFrame(columns=['based symptom', 'support', 'added symptom', 'confidence', 'lift'])
    df_results_market_basket_analysis['based symptom'] = list_all_based_diagnosis
    df_results_market_basket_analysis['support'] = list_all_support
    df_results_market_basket_analysis['added symptom'] = list_all_added_diagnosis
    df_results_market_basket_analysis['confidence'] = list_all_confidence
    df_results_market_basket_analysis['lift'] = list_all_lift_diagnosis
    return df_results_market_basket_analysis
#%% Prepare Data for Market-Basket Analysis
def get_data_for_market_basket_analysis(df):
    df['symptoms_all'] = ""
    list_symptoms = []
    for i in range(0, df.shape[0]):
        symptoms = [df['SYMPTOM1'].iloc[i], df['SYMPTOM2'].iloc[i], df['SYMPTOM3'].iloc[i], df['SYMPTOM4'].iloc[i], df['SYMPTOM5'].iloc[i]]
        list_symptoms.append([v for v in symptoms if v!="" and v.lower()!='no adverse event'and v.lower()!= 'caesarean section' and v.lower()!= 'delivery' and v.lower()!= 'exposure during pregnancy'])
    df['symptoms_all'] = list_symptoms
    return df

"""####MBA: TDAP

- 0.7 and 0.8 for minimum confidence values
- 1.0 and 1.5 for minimum lift values
- used two different minimum lift values and minimum confidence values. This makes sure that all symptom associations that could be reported are
- support values were subject to change. Having a change in this parameter gave results that are relavant and otherwise wouldn't have been reported.
"""

# Symptoms for market-basket analysis
TDAP_PreCOVID_Data_1 = get_data_for_market_basket_analysis(TDAP_PreCOVID_Data)


# set parameters
min_support = 0.01
min_confidence = 0.8
min_lift = 1.0
min_length = 2



TDAP_PreCOVID_Data_1_MBAResults = get_market_basket_analysis_results(TDAP_PreCOVID_Data_1['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(TDAP_PreCOVID_Data_1_MBAResults['based symptom']) if v!=[]]
TDAP_PreCOVID_Data_1_MBAResults = TDAP_PreCOVID_Data_1_MBAResults.iloc[inds_inc, :].copy()
TDAP_PreCOVID_Data_1_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/TDAP_PreCOVID_Data_1_MBAResults.csv")

# Symptoms for market-basket analysis
TDAP_PreCOVID_Data_2 = get_data_for_market_basket_analysis(TDAP_PreCOVID_Data)


# set parameters
min_support = 0.01
min_confidence = 0.7
min_lift = 1.5
min_length = 2



TDAP_PreCOVID_Data_2_MBAResults = get_market_basket_analysis_results(TDAP_PreCOVID_Data_2['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(TDAP_PreCOVID_Data_2_MBAResults['based symptom']) if v!=[]]
TDAP_PreCOVID_Data_2_MBAResults = TDAP_PreCOVID_Data_2_MBAResults.iloc[inds_inc, :].copy().sort_values("lift")
TDAP_PreCOVID_Data_2_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/TDAP_PreCOVID_Data_2_MBAResults.csv")

TDAP_PreCOVID_Data_1_MBAResults.sort_values("lift")

#Saved the results into a csv to use for creating the graph. This was done because some of the results were very large and it wasn't practical. This was done for all results!
TDAP_PreCOVID_Data_1_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/TDAP_PreCOVID_Data_1_MBAResults.csv")
# Scatter plot with arrows
plt.figure(figsize=(8,8))
plt.scatter(TDAP_PreCOVID_Data_1_MBAResults['confidence'], TDAP_PreCOVID_Data_1_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(TDAP_PreCOVID_Data_1_MBAResults)):
    based_symptom = TDAP_PreCOVID_Data_1_MBAResults['based symptom'][i]
    added_symptom = TDAP_PreCOVID_Data_1_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(TDAP_PreCOVID_Data_1_MBAResults['confidence'][i], TDAP_PreCOVID_Data_1_MBAResults['lift'][i]),
                 xytext=(TDAP_PreCOVID_Data_1_MBAResults['confidence'][i] + arrow_length, TDAP_PreCOVID_Data_1_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('TDAP MBA 1 Pre-COVID Results: Associations between Symptoms (Based on Confidence and Lift)', fontsize= 30, pad= 30)
plt.grid(True)
plt.show()

TDAP_PreCOVID_Data_2_MBAResults.sort_values("lift")

TDAP_PreCOVID_Data_2_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/TDAP_PreCOVID_Data_2_MBAResults.csv")
# Scatter plot with arrows
plt.figure(figsize=(10, 8))
plt.scatter(TDAP_PreCOVID_Data_2_MBAResults['confidence'], TDAP_PreCOVID_Data_2_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(TDAP_PreCOVID_Data_2_MBAResults)):
    based_symptom = TDAP_PreCOVID_Data_2_MBAResults['based symptom'][i]
    added_symptom = TDAP_PreCOVID_Data_2_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(TDAP_PreCOVID_Data_2_MBAResults['confidence'][i], TDAP_PreCOVID_Data_2_MBAResults['lift'][i]),
                 xytext=(TDAP_PreCOVID_Data_2_MBAResults['confidence'][i] + arrow_length, TDAP_PreCOVID_Data_2_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('TDAP MBA 2 Pre-COVID Results : Associations between Symptoms (Based on Confidence and Lift)', pad = 40, fontsize = 30)
plt.grid(True)
plt.show()

"""####MBA: Flu Vaccine"""

# Symptoms for market-basket analysis
FLU_PreCOVID_Data_1 = get_data_for_market_basket_analysis(FLU_PreCOVID_Data)


# set parameters
min_support = 0.01
min_confidence = 0.8
min_lift = 1.0
min_length = 2


FLU_PreCOVID_Data_1_MBAResults = get_market_basket_analysis_results(FLU_PreCOVID_Data_1['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(FLU_PreCOVID_Data_1_MBAResults['based symptom']) if v!=[]]
FLU_PreCOVID_Data_1_MBAResults = FLU_PreCOVID_Data_1_MBAResults.iloc[inds_inc, :].copy()
FLU_PreCOVID_Data_1_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/FLU_PreCOVID_Data_1_MBAResults.csv")

# Symptoms for market-basket analysis
FLU_PreCOVID_Data_2 = get_data_for_market_basket_analysis(FLU_PreCOVID_Data)


# set parameters
min_support = 0.01
min_confidence = 0.7
min_lift = 1.5
min_length = 2



FLU_PreCOVID_Data_2_MBAResults = get_market_basket_analysis_results(FLU_PreCOVID_Data_2['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(FLU_PreCOVID_Data_2_MBAResults['based symptom']) if v!=[]]
FLU_PreCOVID_Data_2_MBAResults = FLU_PreCOVID_Data_2_MBAResults.iloc[inds_inc, :].copy()
FLU_PreCOVID_Data_2_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/FLU_PreCOVID_Data_2_MBAResults.csv")

FLU_PreCOVID_Data_1_MBAResults.sort_values("lift")

FLU_PreCOVID_Data_1_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/FLU_PreCOVID_Data_1_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(10, 8))
plt.scatter(FLU_PreCOVID_Data_1_MBAResults['confidence'], FLU_PreCOVID_Data_1_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(FLU_PreCOVID_Data_1_MBAResults)):
    based_symptom = FLU_PreCOVID_Data_1_MBAResults['based symptom'][i]
    added_symptom = FLU_PreCOVID_Data_1_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(FLU_PreCOVID_Data_1_MBAResults['confidence'][i], FLU_PreCOVID_Data_1_MBAResults['lift'][i]),
                 xytext=(FLU_PreCOVID_Data_1_MBAResults['confidence'][i] + arrow_length, FLU_PreCOVID_Data_1_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))


# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('Influenza MBA 1 Pre-COVID Results: Associations between Symptoms (Based on Confidence and Lift)', fontsize = 30, pad= 40)
plt.grid(True)
plt.show()

FLU_PreCOVID_Data_2_MBAResults.sort_values("lift")

FLU_PreCOVID_Data_2_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/FLU_PreCOVID_Data_2_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(10, 8))
plt.scatter(FLU_PreCOVID_Data_2_MBAResults['confidence'], FLU_PreCOVID_Data_2_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(FLU_PreCOVID_Data_2_MBAResults)):
    based_symptom = FLU_PreCOVID_Data_2_MBAResults['based symptom'][i]
    added_symptom = FLU_PreCOVID_Data_2_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(FLU_PreCOVID_Data_2_MBAResults['confidence'][i], FLU_PreCOVID_Data_2_MBAResults['lift'][i]),
                 xytext=(FLU_PreCOVID_Data_2_MBAResults['confidence'][i] + arrow_length, FLU_PreCOVID_Data_2_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('Influenza MBA 2 Pre-COVID Results: Associations between Symptoms (Based on Confidence and Lift)', fontsize = 30, pad = 40)
plt.grid(True)
plt.show()

"""####MBA: Hepatitis A Vaccine"""

# Symptoms for market-basket analysis
HEPA_PreCOVID_Data_1 = get_data_for_market_basket_analysis(HEPA_PreCOVID_Data)


# set parameters
min_support = 0.05
min_confidence = 0.8
min_lift = 1.0
min_length = 2

#year = "2018"

HEPA_PreCOVID_Data_1_MBAResults = get_market_basket_analysis_results(HEPA_PreCOVID_Data_1['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(HEPA_PreCOVID_Data_1_MBAResults['based symptom']) if v!=[]]
HEPA_PreCOVID_Data_1_MBAResults = HEPA_PreCOVID_Data_1_MBAResults.iloc[inds_inc, :].copy()
HEPA_PreCOVID_Data_1_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HEPA_PreCOVID_Data_1_MBAResults.csv")

# Symptoms for market-basket analysis
HEPA_PreCOVID_Data_2 = get_data_for_market_basket_analysis(HEPA_PreCOVID_Data)


# set parameters
min_support = 0.05
min_confidence = 0.7
min_lift = 1.5
min_length = 2

#year = "2018"

HEPA_PreCOVID_Data_2_MBAResults = get_market_basket_analysis_results(HEPA_PreCOVID_Data_2['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(HEPA_PreCOVID_Data_2_MBAResults['based symptom']) if v!=[]]
HEPA_PreCOVID_Data_2_MBAResults = HEPA_PreCOVID_Data_2_MBAResults.iloc[inds_inc, :].copy()
HEPA_PreCOVID_Data_2_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HEPA_PreCOVID_Data_2_MBAResults.csv")

pd.set_option('display.max_rows', None)

HEPA_PreCOVID_Data_1_MBAResults.sort_values("lift")

HEPA_PreCOVID_Data_1_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HEPA_PreCOVID_Data_1_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(10,8))
plt.scatter(HEPA_PreCOVID_Data_1_MBAResults['confidence'], HEPA_PreCOVID_Data_1_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(HEPA_PreCOVID_Data_1_MBAResults)):
    based_symptom = HEPA_PreCOVID_Data_1_MBAResults['based symptom'][i]
    added_symptom = HEPA_PreCOVID_Data_1_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(HEPA_PreCOVID_Data_1_MBAResults['confidence'][i], HEPA_PreCOVID_Data_1_MBAResults['lift'][i]),
                 xytext=(HEPA_PreCOVID_Data_1_MBAResults['confidence'][i] + arrow_length, HEPA_PreCOVID_Data_1_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('Hepatisis A MBA 1 Pre-COVID Results: Associations between Symptoms (Based on Confidence and Lift)',fontsize = 30, pad = 40)
plt.grid(True)
plt.show()

len(HEPA_PreCOVID_Data_1_MBAResults)

HEPA_PreCOVID_Data_2_MBAResults.sort_values("lift")

len(HEPA_PreCOVID_Data_2_MBAResults)

HEPA_PreCOVID_Data_2_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HEPA_PreCOVID_Data_2_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(10,8))
plt.scatter(HEPA_PreCOVID_Data_2_MBAResults['confidence'], HEPA_PreCOVID_Data_2_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(HEPA_PreCOVID_Data_2_MBAResults)):
    based_symptom = HEPA_PreCOVID_Data_2_MBAResults['based symptom'][i]
    added_symptom = HEPA_PreCOVID_Data_2_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(HEPA_PreCOVID_Data_2_MBAResults['confidence'][i], HEPA_PreCOVID_Data_2_MBAResults['lift'][i]),
                 xytext=(HEPA_PreCOVID_Data_2_MBAResults['confidence'][i] + arrow_length, HEPA_PreCOVID_Data_2_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('Hepatisis A MBA 2 Pre-COVID Results: Associations between Symptoms (Based on Confidence and Lift)', fontsize = 30, pad = 30)
plt.grid(True)
plt.show()

"""####MBA: Hepatitis B Vaccine"""

# Symptoms for market-basket analysis
HEPB_PreCOVID_Data_1 = get_data_for_market_basket_analysis(HEPB_PreCOVID_Data)


# set parameters
min_support = 0.02
min_confidence = 0.8
min_lift = 1.0
min_length = 2


HEPB_PreCOVID_Data_1_MBAResults = get_market_basket_analysis_results(HEPB_PreCOVID_Data_1['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(HEPB_PreCOVID_Data_1_MBAResults['based symptom']) if v!=[]]
HEPB_PreCOVID_Data_1_MBAResults = HEPB_PreCOVID_Data_1_MBAResults.iloc[inds_inc, :].copy()
HEPB_PreCOVID_Data_1_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HEPB_PreCOVID_Data_1_MBAResults.csv")

# Symptoms for market-basket analysis
HEPB_PreCOVID_Data_2 = get_data_for_market_basket_analysis(HEPB_PreCOVID_Data)


# set parameters
min_support = 0.02
min_confidence = 0.7
min_lift = 1.5
min_length = 2


HEPB_PreCOVID_Data_2_MBAResults = get_market_basket_analysis_results(HEPB_PreCOVID_Data_2['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(HEPB_PreCOVID_Data_2_MBAResults['based symptom']) if v!=[]]
HEPB_PreCOVID_Data_2_MBAResults = HEPB_PreCOVID_Data_2_MBAResults.iloc[inds_inc, :].copy()
HEPB_PreCOVID_Data_2_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HEPB_PreCOVID_Data_2_MBAResults.csv")

HEPB_PreCOVID_Data_1_MBAResults.sort_values("lift")

HEPB_PreCOVID_Data_1_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HEPB_PreCOVID_Data_1_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(8, 6))
plt.scatter(HEPB_PreCOVID_Data_1_MBAResults['confidence'], HEPB_PreCOVID_Data_1_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(HEPB_PreCOVID_Data_1_MBAResults)):
    based_symptom = HEPB_PreCOVID_Data_1_MBAResults['based symptom'][i]
    added_symptom = HEPB_PreCOVID_Data_1_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(HEPB_PreCOVID_Data_1_MBAResults['confidence'][i], HEPB_PreCOVID_Data_1_MBAResults['lift'][i]),
                 xytext=(HEPB_PreCOVID_Data_1_MBAResults['confidence'][i] + arrow_length, HEPB_PreCOVID_Data_1_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('Hepatisis B MBA 1 Pre-COVID Results: Associations between Symptoms (Based on Confidence and Lift)', fontsize = 30,pad=30)
plt.grid(True)
plt.show()

HEPB_PreCOVID_Data_2_MBAResults.sort_values("lift")

HEPB_PreCOVID_Data_2_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HEPB_PreCOVID_Data_2_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(10,8))
plt.scatter(HEPB_PreCOVID_Data_2_MBAResults['confidence'], HEPB_PreCOVID_Data_2_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(HEPB_PreCOVID_Data_2_MBAResults)):
    based_symptom = HEPB_PreCOVID_Data_2_MBAResults['based symptom'][i]
    added_symptom = HEPB_PreCOVID_Data_2_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(HEPB_PreCOVID_Data_2_MBAResults['confidence'][i], HEPB_PreCOVID_Data_2_MBAResults['lift'][i]),
                 xytext=(HEPB_PreCOVID_Data_2_MBAResults['confidence'][i] + arrow_length, HEPB_PreCOVID_Data_2_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('Hepatisis B MBA 2 Pre-COVID Results: Associations between Symptoms (Based on Confidence and Lift)', fontsize = 30, pad=30)
plt.grid(True)
plt.show()

"""####MBA: MMR Vaccine"""

# Symptoms for market-basket analysis
MMR_PreCOVID_Data_1 = get_data_for_market_basket_analysis(MMR_PreCOVID_Data)



# set parameters
min_support = 0.01
min_confidence = 0.8
min_lift = 1.0
min_length = 2


MMR_PreCOVID_Data_1_MBAResults = get_market_basket_analysis_results(MMR_PreCOVID_Data_1['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(MMR_PreCOVID_Data_1_MBAResults['based symptom']) if v!=[]]
MMR_PreCOVID_Data_1_MBAResults = MMR_PreCOVID_Data_1_MBAResults.iloc[inds_inc, :].copy()
MMR_PreCOVID_Data_1_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/MMR_PreCOVID_Data_1_MBAResults.csv")

# Symptoms for market-basket analysis
MMR_PreCOVID_Data_2 = get_data_for_market_basket_analysis(MMR_PreCOVID_Data)


# set parameters
min_support = 0.01
min_confidence = 0.7
min_lift = 1.5
min_length = 2


MMR_PreCOVID_Data_2_MBAResults = get_market_basket_analysis_results(MMR_PreCOVID_Data_2['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(MMR_PreCOVID_Data_2_MBAResults['based symptom']) if v!=[]]
MMR_PreCOVID_Data_2_MBAResults = MMR_PreCOVID_Data_2_MBAResults.iloc[inds_inc, :].copy()
MMR_PreCOVID_Data_2_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/MMR_PreCOVID_Data_2_MBAResults.csv")

MMR_PreCOVID_Data_1_MBAResults.sort_values("lift")

MMR_PreCOVID_Data_1_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/MMR_PreCOVID_Data_1_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(8, 6))
plt.scatter(MMR_PreCOVID_Data_1_MBAResults['confidence'], MMR_PreCOVID_Data_1_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(MMR_PreCOVID_Data_1_MBAResults)):
    based_symptom = MMR_PreCOVID_Data_1_MBAResults['based symptom'][i]
    added_symptom = MMR_PreCOVID_Data_1_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(MMR_PreCOVID_Data_1_MBAResults['confidence'][i], MMR_PreCOVID_Data_1_MBAResults['lift'][i]),
                 xytext=(MMR_PreCOVID_Data_1_MBAResults['confidence'][i] + arrow_length, MMR_PreCOVID_Data_1_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('MMR MBA 1 Pre-COVID Results: Associations between Symptoms (Based on Confidence and Lift)', pad=60, fontsize=30)
plt.grid(True)
plt.show()

MMR_PreCOVID_Data_2_MBAResults.sort_values("lift")

MMR_PreCOVID_Data_2_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/MMR_PreCOVID_Data_2_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(6, 6))
plt.scatter(MMR_PreCOVID_Data_2_MBAResults['confidence'], MMR_PreCOVID_Data_2_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(MMR_PreCOVID_Data_2_MBAResults)):
    based_symptom = MMR_PreCOVID_Data_2_MBAResults['based symptom'][i]
    added_symptom = MMR_PreCOVID_Data_2_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(MMR_PreCOVID_Data_2_MBAResults['confidence'][i], MMR_PreCOVID_Data_2_MBAResults['lift'][i]),
                 xytext=(MMR_PreCOVID_Data_2_MBAResults['confidence'][i] + arrow_length, MMR_PreCOVID_Data_2_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('MMR MBA 2 Pre-COVID Results: Associations between Symptoms (Based on Confidence and Lift)', pad=60)
plt.grid(True)
plt.show()

"""####MBA: HPV Vaccine"""

# Symptoms for market-basket analysis
HPV_PreCOVID_Data_1 = get_data_for_market_basket_analysis(HPV_PreCOVID_Data)



# set parameters
min_support = 0.01
min_confidence = 0.8
min_lift = 1.0
min_length = 2


HPV_PreCOVID_Data_1_MBAResults = get_market_basket_analysis_results(HPV_PreCOVID_Data_1['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(HPV_PreCOVID_Data_1_MBAResults['based symptom']) if v!=[]]
HPV_PreCOVID_Data_1_MBAResults = HPV_PreCOVID_Data_1_MBAResults.iloc[inds_inc, :].copy()
HPV_PreCOVID_Data_1_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HPV_PreCOVID_Data_1_MBAResults.csv")

# Symptoms for market-basket analysis
HPV_PreCOVID_Data_2 = get_data_for_market_basket_analysis(HPV_PreCOVID_Data)


# set parameters
min_support = 0.01
min_confidence = 0.7
min_lift = 1.5
min_length = 2


HPV_PreCOVID_Data_2_MBAResults = get_market_basket_analysis_results(HPV_PreCOVID_Data_2['symptoms_all'], min_support=min_support, min_confidence=min_confidence, min_lift=min_lift, min_length=min_length)
inds_inc = [i for (i,v) in enumerate(HPV_PreCOVID_Data_2_MBAResults['based symptom']) if v!=[]]
HPV_PreCOVID_Data_2_MBAResults = HPV_PreCOVID_Data_2_MBAResults.iloc[inds_inc, :].copy()
HPV_PreCOVID_Data_2_MBAResults.to_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HPV_PreCOVID_Data_2_MBAResults.csv")

HPV_PreCOVID_Data_1_MBAResults

HPV_PreCOVID_Data_1_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HPV_PreCOVID_Data_1_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(10,8))
plt.scatter(HPV_PreCOVID_Data_1_MBAResults['confidence'], HPV_PreCOVID_Data_1_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(HPV_PreCOVID_Data_1_MBAResults)):
    based_symptom = HPV_PreCOVID_Data_1_MBAResults['based symptom'][i]
    added_symptom = HPV_PreCOVID_Data_1_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(HPV_PreCOVID_Data_1_MBAResults['confidence'][i], HPV_PreCOVID_Data_1_MBAResults['lift'][i]),
                 xytext=(HPV_PreCOVID_Data_1_MBAResults['confidence'][i] + arrow_length, HPV_PreCOVID_Data_1_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('HPV MBA 1 Pre-COVID Results: Associations between Symptoms (Based on Confidence and Lift)', pad=30, fontsize = 30)
plt.grid(True)
plt.show()

HPV_PreCOVID_Data_2_MBAResults

HPV_PreCOVID_Data_2_MBAResults = pd.read_csv("/content/drive/MyDrive/CaptsoneHIDS510ShivaniD/OutputFiles/HPV_PreCOVID_Data_2_MBAResults.csv")

# Scatter plot with arrows
plt.figure(figsize=(10,8))
plt.scatter(HPV_PreCOVID_Data_2_MBAResults['confidence'], HPV_PreCOVID_Data_2_MBAResults['lift'], marker='o', color='blue', s=100)

# Add arrows and text for each point
arrow_length = 0.05
for i in range(len(HPV_PreCOVID_Data_2_MBAResults)):
    based_symptom = HPV_PreCOVID_Data_2_MBAResults['based symptom'][i]
    added_symptom = HPV_PreCOVID_Data_2_MBAResults['added symptom'][i]
    plt.annotate(f"{based_symptom} -> {added_symptom}", xy=(HPV_PreCOVID_Data_2_MBAResults['confidence'][i], HPV_PreCOVID_Data_2_MBAResults['lift'][i]),
                 xytext=(HPV_PreCOVID_Data_2_MBAResults['confidence'][i] + arrow_length, HPV_PreCOVID_Data_2_MBAResults['lift'][i] + 1),
                 arrowprops=dict(arrowstyle="->", color='black'),
                 textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgray'))

# Labels/Titles
plt.xlabel('Confidence')
plt.ylabel('Lift')
plt.title('HPV MBA 2 Pre-COVID Results: Associations between Symptoms (Based on Confidence and Lift)', fontsize = 30, pad=60)
plt.grid(True)
plt.show()